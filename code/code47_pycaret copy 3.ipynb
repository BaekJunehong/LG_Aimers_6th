{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 난임 환자 대상 임신 성공 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGAimers 6th 온라인 해커톤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy scikit-learn matplotlib pycaret lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "Total_train = pd.read_csv('../data/Total_train_dataset_47.csv')\n",
    "Total_test = pd.read_csv('../data/Total_test_dataset_47.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 열을 제외한 특성과 타겟 변수 분리\n",
    "Total_X = Total_train.drop(['임신_성공_여부', 'ID'], axis=1)\n",
    "Total_y = Total_train['임신_성공_여부']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 로드\n",
    "Total_train = pd.read_csv('../data/Total_train_dataset_47.csv')\n",
    "\n",
    "# ID 열을 제외한 특성과 타겟 변수 분리\n",
    "Total_X = Total_train.drop(['임신_성공_여부', 'ID'], axis=1)\n",
    "Total_y = Total_train['임신_성공_여부']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_categorical_columns = [\n",
    "    \"시술_당시_나이\",\n",
    "    \"난자_기증자_나이\",\n",
    "    \"정자_기증자_나이\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 범주형 변수를 문자열로 변환\n",
    "Total_X[Total_categorical_columns] = Total_X[Total_categorical_columns].astype(str)\n",
    "Total_test[Total_categorical_columns] = Total_test[Total_categorical_columns].astype(str)\n",
    "\n",
    "# OrdinalEncoder를 사용하여 범주형 변수 인코딩\n",
    "Total_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "Total_X[Total_categorical_columns] = Total_encoder.fit_transform(Total_X[Total_categorical_columns])\n",
    "Total_test[Total_categorical_columns] = Total_encoder.transform(Total_test[Total_categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "\n",
    "# 특성 이름의 공백을 밑줄로 대체\n",
    "Total_X.columns = Total_X.columns.str.replace(' ', '_')\n",
    "Total_test.columns = Total_test.columns.str.replace(' ', '_')\n",
    "\n",
    "# 데이터 분할\n",
    "Total_X_train, Total_X_test, Total_y_train, Total_y_test = train_test_split(Total_X,\n",
    "                                                                            Total_y,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42,\n",
    "                                                                            stratify=Total_y)\n",
    "\n",
    "# # PyCaret 설정\n",
    "# clf = setup(data=pd.concat([Total_X_train, Total_y_train], axis=1), \n",
    "#             target='임신_성공_여부', \n",
    "#             session_id=42, \n",
    "#             fix_imbalance=True, \n",
    "#             normalize=True, \n",
    "#             feature_selection=True)\n",
    "\n",
    "# # 모델 비교 및 최상의 모델 선택\n",
    "# best_model = compare_models(n_select=5, sort='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최상의 모델 하이퍼파라미터 튜닝\n",
    "# tuned_models = [tune_model(model, optimize='AUC') for model in best_model]\n",
    "\n",
    "# # 메타 모델 리스트\n",
    "# meta_models = [\n",
    "#     LogisticRegression(),\n",
    "#     RandomForestClassifier(random_state=42),\n",
    "#     LGBMClassifier(random_state=42)\n",
    "# ]\n",
    "\n",
    "# # 메타 모델 성능 저장을 위한 리스트\n",
    "# meta_model_performance = []\n",
    "\n",
    "# # 여러 메타 모델로 스태킹 앙상블 수행 및 성능 평가\n",
    "# for meta_model in meta_models:\n",
    "#     stacked_model = stack_models(estimator_list=tuned_models, meta_model=meta_model, fold=5)\n",
    "#     final_model = finalize_model(stacked_model)\n",
    "#     y_pred = predict_model(final_model, data=Total_X_test)\n",
    "    \n",
    "#     accuracy = accuracy_score(Total_y_test, y_pred['Label'])\n",
    "#     f1 = f1_score(Total_y_test, y_pred['Label'])\n",
    "#     auc = roc_auc_score(Total_y_test, y_pred['Score'])\n",
    "    \n",
    "#     meta_model_performance.append((meta_model, accuracy, f1, auc))\n",
    "\n",
    "#     print(f\"Meta Model: {meta_model.__class__.__name__}\")\n",
    "#     print(f\"Accuracy: {accuracy}\")\n",
    "#     print(f\"F1 Score: {f1}\")\n",
    "#     print(f\"AUC: {auc}\")\n",
    "#     print(\"---\")\n",
    "\n",
    "# # 최상의 메타 모델 선택\n",
    "# best_meta_model = max(meta_model_performance, key=lambda x: x[3])[0]  # AUC 기준으로 선택\n",
    "\n",
    "# print(f\"Best Meta Model: {best_meta_model.__class__.__name__}\")\n",
    "\n",
    "# # 최상의 메타 모델로 최종 모델 학습\n",
    "# final_stacked_model = stack_models(estimator_list=tuned_models, meta_model=best_meta_model, fold=5)\n",
    "# final_model = finalize_model(final_stacked_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모든 학습 데이터를 사용하여 최종 모델 학습\n",
    "# final_model.fit(Total_X, Total_y)\n",
    "\n",
    "# # 테스트 데이터 예측\n",
    "# Total_pred_scores = final_model.decision_function(Total_test.drop('ID', axis=1))\n",
    "\n",
    "# # 예측 점수를 테스트 데이터에 추가\n",
    "# Total_test['probability'] = Total_pred_scores\n",
    "\n",
    "# # 최종 제출 파일 생성\n",
    "# submission = Total_test[['ID', 'probability']]\n",
    "# submission = submission.sort_values(by='ID')\n",
    "\n",
    "# # 제출 파일 저장\n",
    "# submission.to_csv('../submission/code47_all_final_model.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 이름의 공백을 밑줄로 대체\n",
    "Total_X.columns = Total_X.columns.str.replace(' ', '_')\n",
    "Total_test.columns = Total_test.columns.str.replace(' ', '_')\n",
    "\n",
    "# 데이터 분할\n",
    "Total_X_train, Total_X_test, Total_y_train, Total_y_test = train_test_split(Total_X,\n",
    "                                                                            Total_y,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42,\n",
    "                                                                            stratify=Total_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250221_235106\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       9.80 GB / 15.86 GB (61.8%)\n",
      "Disk Space Avail:   197.61 GB / 476.30 GB (41.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 450s of the 1800s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-02-22 08:51:11,049\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250221_235106\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Beginning AutoGluon training ... Time limit = 443s\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250221_235106\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Train Data Rows:    227861\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Train Data Columns: 94\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Label Column:       임신_성공_여부\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tAvailable Memory:                    8968.93 MB\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTrain Data (Original)  Memory Usage: 163.41 MB (1.8% of available memory)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\t\tNote: Converting 52 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tUnused Original Features (Count: 6): ['불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_ICI', '특정_시술_유형_IUI', '특정_시술_유형_IVI', '난자채취_적정기간']\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\t('int', []) : 6 | ['불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_ICI', '특정_시술_유형_IUI', '특정_시술_유형_IVI', ...]\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\t('float', []) : 42 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\t('int', [])   : 46 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\t('float', [])     : 32 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '총_생성_배아_수', '미세주입된_난자_수', '미세주입에서_생성된_배아_수', ...]\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\t('int', [])       : 10 | ['총_시술_횟수', '클리닉_내_총_시술_횟수', 'IVF_시술_횟수', 'DI_시술_횟수', '총_임신_횟수', ...]\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t\t('int', ['bool']) : 46 | ['배란_자극_여부', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', '남성_주_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t2.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t88 features in original data used to generate 88 features in processed data.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTrain Data (Processed) Memory Usage: 83.01 MB (0.9% of available memory)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Data preprocessing and feature engineering runtime = 2.27s ...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 293.48s of the 440.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.6533\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t46.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 244.19s of the 391.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.6375\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t44.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 199.61s of the 346.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.45%)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7393\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t13.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t2.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 180.85s of the 327.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.63%)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7392\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t12.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t1.95s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 163.94s of the 310.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7264\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t37.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t13.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 112.15s of the 259.00s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7272\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t39.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t13.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 58.54s of the 205.39s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.36%)\n",
      "\u001b[36m(_ray_fit pid=2560)\u001b[0m \tRan out of time, early stopping on iteration 330.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7391\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t46.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 7.98s of the 154.83s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tWarning: Model is expected to require 73.2s to train, which exceeds the maximum time limit of 7.6s, skipping model...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesGini_BAG_L1.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 6.36s of the 153.21s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tWarning: Model is expected to require 45.6s to train, which exceeds the maximum time limit of 6.1s, skipping model...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L1.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5.27s of the 152.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.96% memory usage per fold, 43.85%/80.00% total).\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=10.96%)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "\u001b[36m(_ray_fit pid=15216)\u001b[0m \tRan out of time, early stopping on iteration 330.\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 142.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.4, 'LightGBM_BAG_L1': 0.32, 'CatBoost_BAG_L1': 0.28}\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7397\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t5.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 137.01s of the 136.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.50%)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7395\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t12.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t1.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 120.10s of the 120.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.49%)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7399\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t10.65s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t1.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 105.01s of the 104.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7585\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t39.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t13.5s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 51.03s of the 50.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 221 due to low time. Expected time usage reduced from 68.7s -> 50.6s...\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7562\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t31.6s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t10.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 8.41s of the 8.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=8.11%)\n",
      "\u001b[36m(_ray_fit pid=9796)\u001b[0m \tRan out of time, early stopping on iteration 27.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7391\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t6.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -2.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \tEnsemble Weights: {'RandomForestGini_BAG_L2': 0.636, 'RandomForestEntr_BAG_L2': 0.364}\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.7595\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t9.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m AutoGluon training complete, total runtime = 454.21s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1291.8 rows/s (28483 batch size)\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250221_235106\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_ray_fit pid=21996)\u001b[0m \tRan out of time, early stopping on iteration 27.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=20024)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         LightGBMXT_BAG_L2       0.739382   0.739533     roc_auc       14.595208     122.924726  162.980497                 0.490110                1.461840          12.593851            2       True          9\n",
      "1       WeightedEnsemble_L2       0.739230   0.739744     roc_auc        1.857754       4.462293   77.909334                 0.011003                0.030001           5.361219            2       True          8\n",
      "2         LightGBMXT_BAG_L1       0.739207   0.739341     roc_auc        0.771176       2.336533   13.867160                 0.771176                2.336533          13.867160            1       True          3\n",
      "3           CatBoost_BAG_L2       0.739052   0.739095     roc_auc       14.253150     121.592913  156.797112                 0.148052                0.130028           6.410466            2       True         13\n",
      "4           LightGBM_BAG_L2       0.738984   0.739908     roc_auc       14.564202     122.642662  161.037081                 0.459104                1.179777          10.650435            2       True         10\n",
      "5           CatBoost_BAG_L1       0.738801   0.739100     roc_auc        0.536455       0.146315   46.648710                 0.536455                0.146315          46.648710            1       True          7\n",
      "6           LightGBM_BAG_L1       0.738603   0.739184     roc_auc        0.539121       1.949444   12.032244                 0.539121                1.949444          12.032244            1       True          4\n",
      "7       WeightedEnsemble_L3       0.733666   0.759503     roc_auc       15.506047     145.366851  230.997883                 0.010002                0.031006           9.310116            3       True         14\n",
      "8   RandomForestEntr_BAG_L2       0.733515   0.756211     roc_auc       14.692346     131.839244  181.986904                 0.587248               10.376359          31.600258            2       True         12\n",
      "9   RandomForestGini_BAG_L2       0.732899   0.758534     roc_auc       14.908796     134.959485  190.087509                 0.803698               13.496600          39.700863            2       True         11\n",
      "10  RandomForestEntr_BAG_L1       0.730101   0.727239     roc_auc        0.776176      13.424040   39.399488                 0.776176               13.424040          39.399488            1       True          6\n",
      "11  RandomForestGini_BAG_L1       0.728714   0.726424     roc_auc        0.792128      13.064968   37.866572                 0.792128               13.064968          37.866572            1       True          5\n",
      "12    KNeighborsUnif_BAG_L1       0.656509   0.653345     roc_auc        5.195800      46.519606    0.290410                 5.195800               46.519606           0.290410            1       True          1\n",
      "13    KNeighborsDist_BAG_L1       0.639953   0.637486     roc_auc        5.494242      44.021980    0.282062                 5.494242               44.021980           0.282062            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t481s\t = DyStack   runtime |\t1319s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 1319s\n",
      "AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250221_235106\"\n",
      "Train Data Rows:    256344\n",
      "Train Data Columns: 94\n",
      "Label Column:       임신_성공_여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8330.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 183.84 MB (2.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 52 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 5): ['불임_원인_-_정자_면역학적_요인', '불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_IVI', '난자채취_적정기간']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['불임_원인_-_정자_면역학적_요인', '불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_IVI', '난자채취_적정기간']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\t\t('int', [])   : 47 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 32 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '총_생성_배아_수', '미세주입된_난자_수', '미세주입에서_생성된_배아_수', ...]\n",
      "\t\t('int', [])       : 10 | ['총_시술_횟수', '클리닉_내_총_시술_횟수', 'IVF_시술_횟수', 'DI_시술_횟수', '총_임신_횟수', ...]\n",
      "\t\t('int', ['bool']) : 47 | ['배란_자극_여부', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', '남성_주_불임_원인', ...]\n",
      "\t1.8s = Fit runtime\n",
      "\t89 features in original data used to generate 89 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 93.63 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1317.05s of the 1317.04s of remaining time.\n",
      "\t0.6545\t = Validation score   (roc_auc)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t65.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1248.88s of the 1248.87s of remaining time.\n",
      "\t0.6389\t = Validation score   (roc_auc)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t65.21s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1182.94s of the 1182.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=7.90%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t16.79s\t = Training   runtime\n",
      "\t2.76s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1161.39s of the 1161.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=8.03%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t14.63s\t = Training   runtime\n",
      "\t2.32s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1142.11s of the 1142.10s of remaining time.\n",
      "\t0.7279\t = Validation score   (roc_auc)\n",
      "\t42.85s\t = Training   runtime\n",
      "\t13.32s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1085.12s of the 1085.11s of remaining time.\n",
      "\t0.7291\t = Validation score   (roc_auc)\n",
      "\t45.05s\t = Training   runtime\n",
      "\t13.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1025.71s of the 1025.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=8.14%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t145.79s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 875.87s of the 875.87s of remaining time.\n",
      "\t0.73\t = Validation score   (roc_auc)\n",
      "\t42.05s\t = Training   runtime\n",
      "\t13.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 819.94s of the 819.94s of remaining time.\n",
      "\t0.7304\t = Validation score   (roc_auc)\n",
      "\t43.65s\t = Training   runtime\n",
      "\t13.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 762.18s of the 762.17s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.31% memory usage per fold, 53.25%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=13.31%)\n",
      "\t0.7372\t = Validation score   (roc_auc)\n",
      "\t357.65s\t = Training   runtime\n",
      "\t2.53s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 401.13s of the 401.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=9.99%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t112.97s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 283.48s of the 283.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=6.89%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=7268, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=7268, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 274.77s of the 274.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=9.56%)\n",
      "2025-02-22 09:16:37,874\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:16:37,879\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:16:37,885\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t19.22s\t = Training   runtime\n",
      "\t3.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 250.77s of the 250.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=9.00%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t88.01s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 158.36s of the 158.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=8.03%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18360, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18360, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 149.83s of the 149.82s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.30% memory usage per fold, 41.22%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=10.30%)\n",
      "2025-02-22 09:18:42,970\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:18:42,976\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:18:42,981\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:18:42,986\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:18:42,991\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t48.98s\t = Training   runtime\n",
      "\t5.43s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 96.69s of the 96.68s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.25% memory usage per fold, 64.99%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=16.25%)\n",
      "\t0.7266\t = Validation score   (roc_auc)\n",
      "\t61.38s\t = Training   runtime\n",
      "\t6.73s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 31.20s of the 31.19s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.74% memory usage per fold, 58.95%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=14.74%)\n",
      "\t0.7351\t = Validation score   (roc_auc)\n",
      "\t27.3s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the -0.00s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.292, 'LightGBMXT_BAG_L1': 0.208, 'NeuralNetFastAI_BAG_L1': 0.167, 'XGBoost_BAG_L1': 0.125, 'LightGBM_BAG_L1': 0.083, 'RandomForestEntr_BAG_L1': 0.042, 'LightGBMLarge_BAG_L1': 0.042, 'CatBoost_r177_BAG_L1': 0.042}\n",
      "\t0.7401\t = Validation score   (roc_auc)\n",
      "\t13.86s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1333.08s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2203.0 rows/s (32043 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250221_235106\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.740099</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>26.471047</td>\n",
       "      <td>813.971878</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>13.857285</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.739515</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.144034</td>\n",
       "      <td>145.793989</td>\n",
       "      <td>0.144034</td>\n",
       "      <td>145.793989</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.739359</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.760641</td>\n",
       "      <td>16.793329</td>\n",
       "      <td>2.760641</td>\n",
       "      <td>16.793329</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_r177_BAG_L1</td>\n",
       "      <td>0.739320</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.126033</td>\n",
       "      <td>88.014823</td>\n",
       "      <td>0.126033</td>\n",
       "      <td>88.014823</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.739224</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.317532</td>\n",
       "      <td>14.625326</td>\n",
       "      <td>2.317532</td>\n",
       "      <td>14.625326</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_r131_BAG_L1</td>\n",
       "      <td>0.739060</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>5.428242</td>\n",
       "      <td>48.980165</td>\n",
       "      <td>5.428242</td>\n",
       "      <td>48.980165</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.738941</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.583351</td>\n",
       "      <td>112.966795</td>\n",
       "      <td>1.583351</td>\n",
       "      <td>112.966795</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.738164</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.381766</td>\n",
       "      <td>19.223351</td>\n",
       "      <td>3.381766</td>\n",
       "      <td>19.223351</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.737189</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.528080</td>\n",
       "      <td>357.651340</td>\n",
       "      <td>2.528080</td>\n",
       "      <td>357.651340</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost_r9_BAG_L1</td>\n",
       "      <td>0.735112</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.165468</td>\n",
       "      <td>27.303221</td>\n",
       "      <td>0.165468</td>\n",
       "      <td>27.303221</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.730391</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>13.340030</td>\n",
       "      <td>43.653433</td>\n",
       "      <td>13.340030</td>\n",
       "      <td>43.653433</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.730041</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>13.114757</td>\n",
       "      <td>42.047262</td>\n",
       "      <td>13.114757</td>\n",
       "      <td>42.047262</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.729058</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>13.593601</td>\n",
       "      <td>45.045641</td>\n",
       "      <td>13.593601</td>\n",
       "      <td>45.045641</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.727898</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>13.320024</td>\n",
       "      <td>42.849306</td>\n",
       "      <td>13.320024</td>\n",
       "      <td>42.849306</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
       "      <td>0.726580</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>6.730541</td>\n",
       "      <td>61.380548</td>\n",
       "      <td>6.730541</td>\n",
       "      <td>61.380548</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.654484</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>65.021010</td>\n",
       "      <td>0.371086</td>\n",
       "      <td>65.021010</td>\n",
       "      <td>0.371086</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.638913</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>65.207834</td>\n",
       "      <td>0.369083</td>\n",
       "      <td>65.207834</td>\n",
       "      <td>0.369083</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_val eval_metric  pred_time_val  \\\n",
       "0           WeightedEnsemble_L2   0.740099     roc_auc      26.471047   \n",
       "1               CatBoost_BAG_L1   0.739515     roc_auc       0.144034   \n",
       "2             LightGBMXT_BAG_L1   0.739359     roc_auc       2.760641   \n",
       "3          CatBoost_r177_BAG_L1   0.739320     roc_auc       0.126033   \n",
       "4               LightGBM_BAG_L1   0.739224     roc_auc       2.317532   \n",
       "5          LightGBM_r131_BAG_L1   0.739060     roc_auc       5.428242   \n",
       "6                XGBoost_BAG_L1   0.738941     roc_auc       1.583351   \n",
       "7          LightGBMLarge_BAG_L1   0.738164     roc_auc       3.381766   \n",
       "8        NeuralNetFastAI_BAG_L1   0.737189     roc_auc       2.528080   \n",
       "9            CatBoost_r9_BAG_L1   0.735112     roc_auc       0.165468   \n",
       "10        ExtraTreesEntr_BAG_L1   0.730391     roc_auc      13.340030   \n",
       "11        ExtraTreesGini_BAG_L1   0.730041     roc_auc      13.114757   \n",
       "12      RandomForestEntr_BAG_L1   0.729058     roc_auc      13.593601   \n",
       "13      RandomForestGini_BAG_L1   0.727898     roc_auc      13.320024   \n",
       "14  NeuralNetFastAI_r191_BAG_L1   0.726580     roc_auc       6.730541   \n",
       "15        KNeighborsUnif_BAG_L1   0.654484     roc_auc      65.021010   \n",
       "16        KNeighborsDist_BAG_L1   0.638913     roc_auc      65.207834   \n",
       "\n",
       "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   813.971878                0.036009          13.857285            2   \n",
       "1   145.793989                0.144034         145.793989            1   \n",
       "2    16.793329                2.760641          16.793329            1   \n",
       "3    88.014823                0.126033          88.014823            1   \n",
       "4    14.625326                2.317532          14.625326            1   \n",
       "5    48.980165                5.428242          48.980165            1   \n",
       "6   112.966795                1.583351         112.966795            1   \n",
       "7    19.223351                3.381766          19.223351            1   \n",
       "8   357.651340                2.528080         357.651340            1   \n",
       "9    27.303221                0.165468          27.303221            1   \n",
       "10   43.653433               13.340030          43.653433            1   \n",
       "11   42.047262               13.114757          42.047262            1   \n",
       "12   45.045641               13.593601          45.045641            1   \n",
       "13   42.849306               13.320024          42.849306            1   \n",
       "14   61.380548                6.730541          61.380548            1   \n",
       "15    0.371086               65.021010           0.371086            1   \n",
       "16    0.369083               65.207834           0.369083            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         17  \n",
       "1        True          7  \n",
       "2        True          3  \n",
       "3        True         13  \n",
       "4        True          4  \n",
       "5        True         14  \n",
       "6        True         11  \n",
       "7        True         12  \n",
       "8        True         10  \n",
       "9        True         16  \n",
       "10       True          9  \n",
       "11       True          8  \n",
       "12       True          6  \n",
       "13       True          5  \n",
       "14       True         15  \n",
       "15       True          1  \n",
       "16       True          2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 09:23:32,097\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:23:32,099\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:23:32,101\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:23:32,103\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:25:42,896\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-22 09:25:42,899\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터를 합쳐서 DataFrame 생성\n",
    "train_data = pd.concat([Total_X_train, Total_y_train], axis=1)\n",
    "test_data = pd.concat([Total_X_test, Total_y_test], axis=1)\n",
    "\n",
    "# 전체 데이터를 하나로 합침\n",
    "combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "\n",
    "# 타겟 컬럼 이름\n",
    "label = Total_y_train.name\n",
    "eval_metric = 'roc_auc'\n",
    "time_limit = 60 * 30  # 30분\n",
    "\n",
    "# 모델 학습\n",
    "predictor = TabularPredictor(\n",
    "    label=label, eval_metric=eval_metric\n",
    ").fit(combined_data, presets='best_quality', time_limit=time_limit)\n",
    "\n",
    "# 리더보드 출력\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.7402670997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_test 데이터의 타겟 변수 예측\n",
    "Total_pred_proba = predictor.predict_proba(Total_test.drop('ID', axis=1))\n",
    "Total_test['probability'] = Total_pred_proba.iloc[:, 1]\n",
    "\n",
    "# 최종 제출 파일 생성\n",
    "submission = Total_test[['ID', 'probability']]\n",
    "submission = submission.sort_values(by='ID')\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission.to_csv('../submission/code47_autogluon.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
