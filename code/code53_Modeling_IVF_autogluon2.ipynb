{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 난임 환자 대상 임신 성공 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGAimers 6th 온라인 해커톤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "IVF_train = pd.read_csv('../data/IVF_train_dataset_53.csv')\n",
    "IVF_test = pd.read_csv('../data/IVF_test_dataset_53.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon.core as ag\n",
    "\n",
    "train_data = TabularDataset(IVF_train)\n",
    "test_data = TabularDataset(IVF_test)\n",
    "\n",
    "label = '임신_성공_여부'\n",
    "eval_metric = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ag-20250224_code53_IVF\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       10.00 GB / 15.86 GB (63.1%)\n",
      "Disk Space Avail:   179.75 GB / 476.30 GB (37.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-02-24 22:33:14,440\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_code53_IVF\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Beginning AutoGluon training ... Time limit = 1793s\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_code53_IVF\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Train Data Rows:    222268\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Train Data Columns: 95\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Label Column:       임신_성공_여부\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tAvailable Memory:                    9331.37 MB\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tTrain Data (Original)  Memory Usage: 172.54 MB (1.8% of available memory)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t\tNote: Converting 49 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tUnused Original Features (Count: 4): ['ID', '불임_원인_-_정자_면역학적_요인', '불임_원인_-_정자_운동성', '배란_유도_유형_기록되지않은시행']\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('bool', [])   : 1 | ['배란_유도_유형_기록되지않은시행']\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('int', [])    : 2 | ['불임_원인_-_정자_면역학적_요인', '불임_원인_-_정자_운동성']\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('object', []) : 1 | ['ID']\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('float', []) : 43 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('int', [])   : 48 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('float', [])     : 33 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '총_생성_배아_수', '미세주입된_난자_수', '미세주입에서_생성된_배아_수', ...]\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('int', [])       : 12 | ['총_시술_횟수', '클리닉_내_총_시술_횟수', 'IVF_시술_횟수', 'DI_시술_횟수', '총_임신_횟수', ...]\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t('int', ['bool']) : 46 | ['배란_자극_여부', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', '남성_주_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t2.4s = Fit runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t91 features in original data used to generate 91 features in processed data.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tTrain Data (Processed) Memory Usage: 86.06 MB (0.9% of available memory)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Data preprocessing and feature engineering runtime = 2.59s ...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1193.44s of the 1790.59s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.6495\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.3s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t41.71s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1149.02s of the 1746.17s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.6342\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t41.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1107.15s of the 1704.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=6.56%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.738\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t7.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t1.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 1095.87s of the 1693.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=6.74%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7375\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t6.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t1.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1085.70s of the 1682.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7267\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t37.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t13.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1034.13s of the 1631.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7278\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t39.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t13.81s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 980.26s of the 1577.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.66%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7377\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t49.7s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 927.53s of the 1524.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7281\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t36.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t13.43s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 877.11s of the 1474.26s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7284\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t35.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t12.96s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 827.57s of the 1424.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=11.39%)\n",
      "\u001b[36m(_ray_fit pid=19756)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_ray_fit pid=15980)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_ray_fit pid=21748)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_ray_fit pid=13392)\u001b[0m No improvement since epoch 8: early stopping\n",
      "\u001b[36m(_ray_fit pid=27704)\u001b[0m No improvement since epoch 9: early stopping\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7345\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t222.66s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t2.65s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 601.52s of the 1198.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.03%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7373\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t151.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.95s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 446.17s of the 1043.32s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=6.21%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=29620, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=29620, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 439.94s of the 1037.08s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.63%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7367\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t8.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t1.79s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 427.52s of the 1024.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.53%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7378\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t30.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 394.00s of the 991.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=6.32%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=2556, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=2556, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 387.81s of the 984.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.27%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7378\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t18.97s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t4.93s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 364.82s of the 961.97s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=13.17%)\n",
      "\u001b[36m(_ray_fit pid=27364)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 13)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7343\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t281.01s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t6.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 79.33s of the 676.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.83%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_ray_fit pid=12592)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 13)\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=13424)\u001b[0m \tRan out of time, early stopping on iteration 402.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7376\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t63.2s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 12.43s of the 609.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.36%)\n",
      "\u001b[36m(_ray_fit pid=26964)\u001b[0m \tRan out of time, early stopping on iteration 391. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=26964)\u001b[0m \t[391]\tvalid_set's binary_logloss: 0.491851\n",
      "\u001b[36m(_ray_fit pid=19600)\u001b[0m \tRan out of time, early stopping on iteration 403.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7363\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t10.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t3.23s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 595.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.267, 'CatBoost_r177_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.133, 'LightGBM_BAG_L1': 0.067, 'RandomForestEntr_BAG_L1': 0.067, 'XGBoost_BAG_L1': 0.067, 'LightGBMLarge_BAG_L1': 0.067, 'LightGBM_r131_BAG_L1': 0.067, 'NeuralNetFastAI_r191_BAG_L1': 0.067}\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7388\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t12.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 582.82s of the 582.75s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=1484)\u001b[0m \tRan out of time, early stopping on iteration 384. Best iteration is:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1484)\u001b[0m \t[384]\tvalid_set's binary_logloss: 0.493181\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.82%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7385\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t7.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.84s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 571.84s of the 571.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.83%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7385\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t7.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.86s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 560.75s of the 560.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7391\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t47.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t14.73s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 498.15s of the 498.07s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.74\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t56.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t15.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 425.92s of the 425.84s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.16%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7386\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t38.69s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 384.10s of the 384.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7426\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t36.78s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t14.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 332.03s of the 331.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7422\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t39.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t14.63s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 277.49s of the 277.42s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=14.10%)\n",
      "\u001b[36m(_ray_fit pid=26108)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_ray_fit pid=8296)\u001b[0m No improvement since epoch 5: early stopping\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7374\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t214.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t2.75s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 59.11s of the 59.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.88%)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7381\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t47.82s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t1.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 7.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.4, 'ExtraTreesEntr_BAG_L2': 0.3, 'RandomForestEntr_BAG_L2': 0.2, 'RandomForestGini_BAG_L2': 0.1}\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.7442\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t19.42s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m AutoGluon training complete, total runtime = 1805.54s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 713.5 rows/s (44454 batch size)\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_code53_IVF\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=7684)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        NeuralNetFastAI_BAG_L2       0.737588   0.737370     roc_auc       23.123468     162.113749  1214.982946                 1.627888                2.749072         214.764887            2       True         26\n",
      "1          CatBoost_r177_BAG_L1       0.737396   0.737784     roc_auc        0.136524       0.078140    30.117981                 0.136524                0.078140          30.117981            1       True         13\n",
      "2               CatBoost_BAG_L1       0.737282   0.737679     roc_auc        0.473515       0.094661    49.702552                 0.473515                0.094661          49.702552            1       True          7\n",
      "3           WeightedEnsemble_L2       0.737162   0.738752     roc_auc        8.381388      33.114728   779.316411                 0.015627                0.021652          12.377635            2       True         18\n",
      "4               CatBoost_BAG_L2       0.737082   0.738564     roc_auc       21.621598     159.455347  1038.906030                 0.126018                0.090670          38.687972            2       True         23\n",
      "5             LightGBMXT_BAG_L2       0.737081   0.738451     roc_auc       21.842125     160.206863  1007.901109                 0.346545                0.842185           7.683050            2       True         19\n",
      "6            CatBoost_r9_BAG_L1       0.736789   0.737611     roc_auc        0.255909       0.698774    63.198443                 0.255909                0.698774          63.198443            1       True         16\n",
      "7                XGBoost_BAG_L2       0.736711   0.738131     roc_auc       22.207379     160.512337  1048.040629                 0.711798                1.147660          47.822571            2       True         27\n",
      "8               LightGBM_BAG_L2       0.736658   0.738515     roc_auc       21.819001     160.227400  1007.731796                 0.323421                0.862723           7.513737            2       True         20\n",
      "9             LightGBMXT_BAG_L1       0.736657   0.737972     roc_auc        0.482062       1.567628     7.787730                 0.482062                1.567628           7.787730            1       True          3\n",
      "10               XGBoost_BAG_L1       0.736596   0.737313     roc_auc        0.949443       0.947987   151.885194                 0.949443                0.947987         151.885194            1       True         11\n",
      "11              LightGBM_BAG_L1       0.736477   0.737546     roc_auc        0.317415       1.052562     6.514059                 0.317415                1.052562           6.514059            1       True          4\n",
      "12         LightGBM_r131_BAG_L1       0.736300   0.737806     roc_auc        1.003395       4.931802    18.967463                 1.003395                4.931802          18.967463            1       True         14\n",
      "13       NeuralNetFastAI_BAG_L1       0.736078   0.734542     roc_auc        2.063150       2.654016   222.663966                 2.063150                2.654016         222.663966            1       True         10\n",
      "14  NeuralNetFastAI_r191_BAG_L1       0.735977   0.734263     roc_auc        1.945641       6.260015   281.009906                 1.945641                6.260015         281.009906            1       True         15\n",
      "15         LightGBMLarge_BAG_L1       0.735329   0.736698     roc_auc        0.450308       1.786969     8.707209                 0.450308                1.786969           8.707209            1       True         12\n",
      "16          LightGBM_r96_BAG_L1       0.734736   0.736349     roc_auc        0.543719       3.234328    10.004113                 0.543719                3.234328          10.004113            1       True         17\n",
      "17          WeightedEnsemble_L3       0.733999   0.744156     roc_auc       24.590807     218.306154  1198.751959                 0.015625                0.031257          19.419631            3       True         28\n",
      "18        ExtraTreesEntr_BAG_L2       0.733565   0.742168     roc_auc       22.271832     173.994497  1039.270267                 0.776251               14.629820          39.052208            2       True         25\n",
      "19        ExtraTreesGini_BAG_L2       0.733130   0.742621     roc_auc       22.223655     173.821613  1036.994782                 0.728075               14.456936          36.776724            2       True         24\n",
      "20      RandomForestEntr_BAG_L2       0.732558   0.739969     roc_auc       22.264274     174.456939  1056.505118                 0.768693               15.092261          56.287060            2       True         22\n",
      "21      RandomForestGini_BAG_L2       0.730599   0.739080     roc_auc       22.302163     174.095880  1047.216337                 0.806582               14.731203          46.998278            2       True         21\n",
      "22        ExtraTreesEntr_BAG_L1       0.725483   0.728397     roc_auc        0.859983      12.956157    35.826207                 0.859983               12.956157          35.826207            1       True          9\n",
      "23        ExtraTreesGini_BAG_L1       0.724519   0.728130     roc_auc        0.861577      13.426085    36.181723                 0.861577               13.426085          36.181723            1       True          8\n",
      "24      RandomForestEntr_BAG_L1       0.723507   0.727850     roc_auc        1.017822      13.813957    39.285268                 1.017822               13.813957          39.285268            1       True          6\n",
      "25      RandomForestGini_BAG_L1       0.722956   0.726658     roc_auc        0.819977      13.026802    37.725800                 0.819977               13.026802          37.725800            1       True          5\n",
      "26        KNeighborsUnif_BAG_L1       0.652924   0.649468     roc_auc        4.418543      41.707455     0.303866                 4.418543               41.707455           0.303866            1       True          1\n",
      "27        KNeighborsDist_BAG_L1       0.634689   0.634189     roc_auc        4.896596      41.127338     0.336578                 4.896596               41.127338           0.336578            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t1843s\t = DyStack   runtime |\t5357s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 5357s\n",
      "AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_code53_IVF\"\n",
      "Train Data Rows:    250052\n",
      "Train Data Columns: 95\n",
      "Label Column:       임신_성공_여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8201.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 194.11 MB (2.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 49 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 3): ['ID', '불임_원인_-_정자_면역학적_요인', '배란_유도_유형_기록되지않은시행']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('bool', [])   : 1 | ['배란_유도_유형_기록되지않은시행']\n",
      "\t\t('int', [])    : 1 | ['불임_원인_-_정자_면역학적_요인']\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 43 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\t\t('int', [])   : 49 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 33 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '총_생성_배아_수', '미세주입된_난자_수', '미세주입에서_생성된_배아_수', ...]\n",
      "\t\t('int', [])       : 12 | ['총_시술_횟수', '클리닉_내_총_시술_횟수', 'IVF_시술_횟수', 'DI_시술_횟수', '총_임신_횟수', ...]\n",
      "\t\t('int', ['bool']) : 47 | ['배란_자극_여부', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', '남성_주_불임_원인', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t92 features in original data used to generate 92 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 97.06 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.66s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5354.08s of the 5354.07s of remaining time.\n",
      "\t0.6512\t = Validation score   (roc_auc)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t63.54s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 5287.61s of the 5287.60s of remaining time.\n",
      "\t0.636\t = Validation score   (roc_auc)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t63.36s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5223.51s of the 5223.49s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.49%)\n",
      "\t0.7381\t = Validation score   (roc_auc)\n",
      "\t8.99s\t = Training   runtime\n",
      "\t1.79s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 5210.81s of the 5210.80s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.66%)\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t7.88s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 5200.55s of the 5200.54s of remaining time.\n",
      "\t0.7272\t = Validation score   (roc_auc)\n",
      "\t41.29s\t = Training   runtime\n",
      "\t15.13s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 5143.37s of the 5143.35s of remaining time.\n",
      "\t0.7282\t = Validation score   (roc_auc)\n",
      "\t43.81s\t = Training   runtime\n",
      "\t15.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 5083.43s of the 5083.41s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.33%)\n",
      "\t0.7379\t = Validation score   (roc_auc)\n",
      "\t57.17s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 5024.30s of the 5024.29s of remaining time.\n",
      "\t0.7281\t = Validation score   (roc_auc)\n",
      "\t40.05s\t = Training   runtime\n",
      "\t14.94s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4968.52s of the 4968.50s of remaining time.\n",
      "\t0.7288\t = Validation score   (roc_auc)\n",
      "\t41.44s\t = Training   runtime\n",
      "\t15.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4911.11s of the 4911.09s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=12.61%)\n",
      "\t0.7343\t = Validation score   (roc_auc)\n",
      "\t168.28s\t = Training   runtime\n",
      "\t2.33s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4740.41s of the 4740.39s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=11.54%)\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t195.24s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4542.59s of the 4542.58s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.25%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14380, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14380, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4537.46s of the 4537.44s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.73%)\n",
      "2025-02-24 23:17:38,806\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:17:38,806\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:17:38,817\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7364\t = Validation score   (roc_auc)\n",
      "\t11.26s\t = Training   runtime\n",
      "\t1.91s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 4523.59s of the 4523.57s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.28%)\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t45.97s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 4475.32s of the 4475.30s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.21%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28332, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28332, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 4470.18s of the 4470.16s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.68%)\n",
      "2025-02-24 23:18:46,350\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:18:46,350\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:18:46,350\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t24.53s\t = Training   runtime\n",
      "\t5.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 4442.41s of the 4442.39s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=13.83%)\n",
      "2025-02-24 23:24:33,406\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:25:46,013\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7332\t = Validation score   (roc_auc)\n",
      "\t639.45s\t = Training   runtime\n",
      "\t6.18s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 3800.01s of the 3800.00s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.57%)\n",
      "\t0.7379\t = Validation score   (roc_auc)\n",
      "\t84.23s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 3713.46s of the 3713.45s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.35%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t48.25s\t = Training   runtime\n",
      "\t10.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 3661.34s of the 3661.33s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.56%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9516, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 3656.15s of the 3656.14s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=15.15%)\n",
      "2025-02-24 23:32:20,573\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:32:20,573\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:32:20,573\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 23:39:20,196\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7359\t = Validation score   (roc_auc)\n",
      "\t647.87s\t = Training   runtime\n",
      "\t4.82s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 3005.26s of the 3005.23s of remaining time.\n",
      "\t0.7208\t = Validation score   (roc_auc)\n",
      "\t206.52s\t = Training   runtime\n",
      "\t14.49s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 2783.34s of the 2783.33s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.52%)\n",
      "\t0.7379\t = Validation score   (roc_auc)\n",
      "\t82.76s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 2698.61s of the 2698.59s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=14.80%)\n",
      "\t0.7351\t = Validation score   (roc_auc)\n",
      "\t102.64s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 2593.42s of the 2593.40s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=12.49%)\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t152.49s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 2438.40s of the 2438.38s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 191 due to low memory. Expected memory usage reduced from 23.51% -> 15.0% of available memory...\n",
      "\t0.7022\t = Validation score   (roc_auc)\n",
      "\t159.91s\t = Training   runtime\n",
      "\t11.23s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 2266.17s of the 2266.16s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.85%)\n",
      "\t0.737\t = Validation score   (roc_auc)\n",
      "\t13.09s\t = Training   runtime\n",
      "\t2.63s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 2250.56s of the 2250.55s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=14.88%)\n",
      "\t0.7328\t = Validation score   (roc_auc)\n",
      "\t600.36s\t = Training   runtime\n",
      "\t6.22s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 1646.94s of the 1646.92s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=13.09%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t387.4s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 1256.76s of the 1256.75s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.00%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=14504, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=14504, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 1251.23s of the 1251.21s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.87%)\n",
      "2025-02-25 00:12:25,305\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-25 00:12:25,309\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-25 00:12:25,311\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-25 00:12:25,314\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t11.6s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 1236.92s of the 1236.90s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.04%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21988, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21988, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 1230.43s of the 1230.41s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=11.49%)\n",
      "2025-02-25 00:12:46,454\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7377\t = Validation score   (roc_auc)\n",
      "\t48.73s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 1179.06s of the 1179.05s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.70% memory usage per fold, 74.81%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=18.70%)\n",
      "2025-02-25 00:19:46,151\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-25 00:19:46,155\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-25 00:19:46,159\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7248\t = Validation score   (roc_auc)\n",
      "\t823.64s\t = Training   runtime\n",
      "\t8.58s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 352.04s of the 352.03s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=13.02%)\n",
      "\t0.7375\t = Validation score   (roc_auc)\n",
      "\t15.33s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 332.85s of the 332.83s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 290 due to low time. Expected time usage reduced from 342.9s -> 332.5s...\n",
      "\t0.7227\t = Validation score   (roc_auc)\n",
      "\t288.27s\t = Training   runtime\n",
      "\t15.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 28.19s of the 28.18s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.14%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t23.4s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 535.41s of the 1.55s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.261, 'XGBoost_BAG_L1': 0.13, 'LightGBMXT_BAG_L1': 0.087, 'CatBoost_r9_BAG_L1': 0.087, 'CatBoost_r137_BAG_L1': 0.087, 'NeuralNetFastAI_BAG_L1': 0.043, 'NeuralNetFastAI_r191_BAG_L1': 0.043, 'NeuralNetFastAI_r102_BAG_L1': 0.043, 'NeuralNetFastAI_r145_BAG_L1': 0.043, 'XGBoost_r89_BAG_L1': 0.043, 'CatBoost_r50_BAG_L1': 0.043, 'XGBoost_r194_BAG_L1': 0.043, 'ExtraTrees_r172_BAG_L1': 0.043}\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t28.82s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5384.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1411.5 rows/s (50011 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_code53_IVF\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# 시간 제한 설정 \n",
    "time_limit =  2 * 60 * 60\n",
    "\n",
    "# # GPU를 사용할 수 없는 모델을 제외하도록 설정\n",
    "# exclude_model_types = [\n",
    "#     'KNN',  # K-Nearest Neighbors\n",
    "#     'RF',   # Random Forest\n",
    "#     'XT',   # Extra Trees\n",
    "#     'LR',   # Linear Regression\n",
    "#     'NN'    # Tabular Neural Network\n",
    "# ]\n",
    "\n",
    "# TabularPredictor 객체 생성 및 학습\n",
    "predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    eval_metric=eval_metric,\n",
    "    path='AutogluonModels/ag-20250224_code53_IVF'  # 모델 저장 경로\n",
    ").fit(\n",
    "    train_data,\n",
    "    presets='best_quality',  # 'best_quality', 'medium_quality', 'good_quality' 등의 프리셋 설정\n",
    "    # num_stack_levels=0,  # 스택 레벨 설정 / dynamic_stacking=True(디폴트)인 경우 무시\n",
    "    num_bag_folds=5,  # 배깅 설정\n",
    "    time_limit=time_limit,  # 시간 제한 설정\n",
    "    # num_gpus=1,  # GPU 사용 설정\n",
    "    # excluded_model_types=exclude_model_types  # 제외할 모델 유형 설정\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          model  score_val eval_metric  pred_time_val  \\\n",
      "0           WeightedEnsemble_L2   0.738832     roc_auc      47.931994   \n",
      "1           LightGBM_r96_BAG_L1   0.738371     roc_auc      10.183154   \n",
      "2             LightGBMXT_BAG_L1   0.738130     roc_auc       1.786680   \n",
      "3           CatBoost_r13_BAG_L1   0.737988     roc_auc       0.140638   \n",
      "4            CatBoost_r9_BAG_L1   0.737905     roc_auc       0.392291   \n",
      "5               CatBoost_BAG_L1   0.737887     roc_auc       0.090179   \n",
      "6          CatBoost_r137_BAG_L1   0.737868     roc_auc       0.110318   \n",
      "7            XGBoost_r89_BAG_L1   0.737778     roc_auc       1.532071   \n",
      "8          CatBoost_r177_BAG_L1   0.737693     roc_auc       0.078135   \n",
      "9           CatBoost_r50_BAG_L1   0.737675     roc_auc       0.280972   \n",
      "10         LightGBM_r131_BAG_L1   0.737671     roc_auc       5.187069   \n",
      "11              LightGBM_BAG_L1   0.737600     roc_auc       1.056209   \n",
      "12               XGBoost_BAG_L1   0.737588     roc_auc       1.019640   \n",
      "13          XGBoost_r194_BAG_L1   0.737484     roc_auc       0.541670   \n",
      "14         LightGBM_r130_BAG_L1   0.737139     roc_auc       1.557231   \n",
      "15          CatBoost_r69_BAG_L1   0.737084     roc_auc       0.091981   \n",
      "16         LightGBM_r188_BAG_L1   0.736954     roc_auc       2.631348   \n",
      "17         LightGBMLarge_BAG_L1   0.736430     roc_auc       1.913644   \n",
      "18           XGBoost_r33_BAG_L1   0.735886     roc_auc       4.820850   \n",
      "19  NeuralNetFastAI_r102_BAG_L1   0.735092     roc_auc       1.734178   \n",
      "20       NeuralNetFastAI_BAG_L1   0.734312     roc_auc       2.327305   \n",
      "21  NeuralNetFastAI_r191_BAG_L1   0.733157     roc_auc       6.175642   \n",
      "22  NeuralNetFastAI_r145_BAG_L1   0.732830     roc_auc       6.221007   \n",
      "23        ExtraTreesEntr_BAG_L1   0.728796     roc_auc      15.190028   \n",
      "24      RandomForestEntr_BAG_L1   0.728154     roc_auc      15.350091   \n",
      "25        ExtraTreesGini_BAG_L1   0.728128     roc_auc      14.941406   \n",
      "26      RandomForestGini_BAG_L1   0.727166     roc_auc      15.128165   \n",
      "27   NeuralNetFastAI_r11_BAG_L1   0.724753     roc_auc       8.581299   \n",
      "28       ExtraTrees_r172_BAG_L1   0.722727     roc_auc      15.593374   \n",
      "29        ExtraTrees_r42_BAG_L1   0.720834     roc_auc      14.486813   \n",
      "30     RandomForest_r195_BAG_L1   0.702212     roc_auc      11.233647   \n",
      "31        KNeighborsUnif_BAG_L1   0.651183     roc_auc      63.544807   \n",
      "32        KNeighborsDist_BAG_L1   0.635952     roc_auc      63.356972   \n",
      "\n",
      "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   2698.747565                0.033691          28.816882            2   \n",
      "1     48.248069               10.183154          48.248069            1   \n",
      "2      8.991666                1.786680           8.991666            1   \n",
      "3    152.494861                0.140638         152.494861            1   \n",
      "4     84.231162                0.392291          84.231162            1   \n",
      "5     57.165525                0.090179          57.165525            1   \n",
      "6     82.757978                0.110318          82.757978            1   \n",
      "7    387.397262                1.532071         387.397262            1   \n",
      "8     45.968285                0.078135          45.968285            1   \n",
      "9     48.732536                0.280972          48.732536            1   \n",
      "10    24.528826                5.187069          24.528826            1   \n",
      "11     7.876485                1.056209           7.876485            1   \n",
      "12   195.241335                1.019640         195.241335            1   \n",
      "13    15.327401                0.541670          15.327401            1   \n",
      "14    11.596799                1.557231          11.596799            1   \n",
      "15    23.397093                0.091981          23.397093            1   \n",
      "16    13.088284                2.631348          13.088284            1   \n",
      "17    11.259363                1.913644          11.259363            1   \n",
      "18   647.865500                4.820850         647.865500            1   \n",
      "19   102.641848                1.734178         102.641848            1   \n",
      "20   168.276151                2.327305         168.276151            1   \n",
      "21   639.452168                6.175642         639.452168            1   \n",
      "22   600.360846                6.221007         600.360846            1   \n",
      "23    41.443587               15.190028          41.443587            1   \n",
      "24    43.811052               15.350091          43.811052            1   \n",
      "25    40.048628               14.941406          40.048628            1   \n",
      "26    41.290650               15.128165          41.290650            1   \n",
      "27   823.635643                8.581299         823.635643            1   \n",
      "28   288.272262               15.593374         288.272262            1   \n",
      "29   206.523653               14.486813         206.523653            1   \n",
      "30   159.913079               11.233647         159.913079            1   \n",
      "31     0.412176               63.544807           0.412176            1   \n",
      "32     0.407718               63.356972           0.407718            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0        True         33  \n",
      "1        True         17  \n",
      "2        True          3  \n",
      "3        True         22  \n",
      "4        True         16  \n",
      "5        True          7  \n",
      "6        True         20  \n",
      "7        True         26  \n",
      "8        True         13  \n",
      "9        True         28  \n",
      "10       True         14  \n",
      "11       True          4  \n",
      "12       True         11  \n",
      "13       True         30  \n",
      "14       True         27  \n",
      "15       True         32  \n",
      "16       True         24  \n",
      "17       True         12  \n",
      "18       True         18  \n",
      "19       True         21  \n",
      "20       True         10  \n",
      "21       True         15  \n",
      "22       True         25  \n",
      "23       True          9  \n",
      "24       True          6  \n",
      "25       True          8  \n",
      "26       True          5  \n",
      "27       True         29  \n",
      "28       True         31  \n",
      "29       True         19  \n",
      "30       True         23  \n",
      "31       True          1  \n",
      "32       True          2  \n"
     ]
    }
   ],
   "source": [
    "print(predictor.leaderboard(silent = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.feature_importance(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 모델 가져오기\n",
    "model_to_use = predictor.model_best\n",
    "\n",
    "# 확률 예측\n",
    "prob_predictions = predictor.predict_proba(test_data, model=model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  probability\n",
      "0  TEST_00000     0.001330\n",
      "1  TEST_00001     0.001405\n",
      "2  TEST_00002     0.148915\n",
      "3  TEST_00003     0.105204\n",
      "4  TEST_00004     0.510218\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 test_data에 추가\n",
    "test_data['probability'] = prob_predictions.iloc[:, 1]\n",
    "\n",
    "# 최종 제출 파일 생성\n",
    "submission = test_data[['ID', 'probability']]\n",
    "submission = submission.sort_values(by='ID')\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission.to_csv('../submission/code53_IVF_lgbm2.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# 예측 결과 확인\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이콘 PUBLIC xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
