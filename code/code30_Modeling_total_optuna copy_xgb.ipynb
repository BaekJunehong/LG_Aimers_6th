{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 난임 환자 대상 임신 성공 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGAimers 6th 온라인 해커톤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "Total_train = pd.read_csv('../data/Total_train_dataset_30_copy.csv')\n",
    "Total_test = pd.read_csv('../data/Total_test_dataset_30_copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 열을 제외한 특성과 타겟 변수 분리\n",
    "Total_X = Total_train.drop(['임신_성공_여부', 'ID'], axis=1)\n",
    "Total_y = Total_train['임신_성공_여부']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_categorical_columns = [\n",
    "    \"시술_시기_코드\",\n",
    "    \"시술_당시_나이\",\n",
    "    \"특정_시술_유형\",\n",
    "    \"배란_유도_유형\",\n",
    "    \"단일_배아_이식_여부\",\n",
    "    \"착상_전_유전_진단_사용_여부\",\n",
    "    \"배아_생성_주요_이유\",\n",
    "    \"총_생성_배아_수\",\n",
    "    \"미세주입된_난자_수\",\n",
    "    \"미세주입에서_생성된_배아_수\",\n",
    "    \"이식된_배아_수\",\n",
    "    \"미세주입_배아_이식_수\",\n",
    "    \"저장된_배아_수\",\n",
    "    \"미세주입_후_저장된_배아_수\",\n",
    "    \"해동된_배아_수\",\n",
    "    \"해동_난자_수\",\n",
    "    \"수집된_신선_난자_수\",\n",
    "    \"저장된_신선_난자_수\",\n",
    "    \"혼합된_난자_수\",\n",
    "    \"파트너_정자와_혼합된_난자_수\",\n",
    "    \"기증자_정자와_혼합된_난자_수\",\n",
    "    \"난자_출처\",\n",
    "    \"정자_출처\",\n",
    "    \"난자_기증자_나이\",\n",
    "    \"정자_기증자_나이\",\n",
    "    \"동결_배아_사용_여부\",\n",
    "    \"신선_배아_사용_여부\",\n",
    "    \"기증_배아_사용_여부\",\n",
    "    \"대리모_여부\",\n",
    "    \"ICSI_배아_이식_비율\",\n",
    "    \"ICSI_배아_생성_비율\",\n",
    "    \"ICSI_성공률\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 범주형 변수를 문자열로 변환\n",
    "Total_X[Total_categorical_columns] = Total_X[Total_categorical_columns].astype(str)\n",
    "Total_test[Total_categorical_columns] = Total_test[Total_categorical_columns].astype(str)\n",
    "\n",
    "# OrdinalEncoder를 사용하여 범주형 변수 인코딩\n",
    "Total_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "Total_X[Total_categorical_columns] = Total_encoder.fit_transform(Total_X[Total_categorical_columns])\n",
    "Total_test[Total_categorical_columns] = Total_encoder.transform(Total_test[Total_categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "Total_X_train, Total_X_test, Total_y_train, Total_y_test = train_test_split(Total_X, Total_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 08:28:24,484] A new study created in memory with name: no-name-244733b4-5e41-4d81-b580-57959454929b\n",
      "[I 2025-02-15 08:35:27,964] Trial 0 finished with value: 0.7332533262315769 and parameters: {'n_estimators': 2213, 'learning_rate': 2.7045131701954626e-05, 'max_depth': 9, 'min_child_weight': 5, 'gamma': 0.5603859092912555, 'subsample': 0.510710140910714, 'colsample_bytree': 0.7993423363993934, 'reg_alpha': 8.03788719493011e-05, 'reg_lambda': 5.000500414927698}. Best is trial 0 with value: 0.7332533262315769.\n",
      "[I 2025-02-15 09:08:18,619] Trial 1 finished with value: 0.7364722178213352 and parameters: {'n_estimators': 6958, 'learning_rate': 0.0003514010575028525, 'max_depth': 12, 'min_child_weight': 8, 'gamma': 4.399564868126501, 'subsample': 0.6383901706326646, 'colsample_bytree': 0.8107178272405731, 'reg_alpha': 0.0024173787508648577, 'reg_lambda': 0.0011660718718697477}. Best is trial 1 with value: 0.7364722178213352.\n",
      "[I 2025-02-15 09:34:03,291] Trial 2 finished with value: 0.733675545844462 and parameters: {'n_estimators': 7624, 'learning_rate': 6.0329672157973945e-05, 'max_depth': 10, 'min_child_weight': 3, 'gamma': 3.775894094715885, 'subsample': 0.9607019439606297, 'colsample_bytree': 0.6378407119240881, 'reg_alpha': 1.8572768882598096e-06, 'reg_lambda': 0.00017278285852981068}. Best is trial 1 with value: 0.7364722178213352.\n",
      "[I 2025-02-15 09:53:13,124] Trial 3 finished with value: 0.7303859192239415 and parameters: {'n_estimators': 7686, 'learning_rate': 5.864828154023164e-05, 'max_depth': 7, 'min_child_weight': 4, 'gamma': 3.1654047817814335, 'subsample': 0.9622395416654499, 'colsample_bytree': 0.5314816053331359, 'reg_alpha': 0.953881092944773, 'reg_lambda': 6.791213316186406e-05}. Best is trial 1 with value: 0.7364722178213352.\n",
      "[I 2025-02-15 10:13:51,628] Trial 4 finished with value: 0.7343469220092589 and parameters: {'n_estimators': 5380, 'learning_rate': 0.0001346617470721684, 'max_depth': 10, 'min_child_weight': 4, 'gamma': 4.038587280510557, 'subsample': 0.6238545477412607, 'colsample_bytree': 0.7146876510750209, 'reg_alpha': 3.3433078245413936e-06, 'reg_lambda': 5.642501429341429}. Best is trial 1 with value: 0.7364722178213352.\n",
      "[I 2025-02-15 10:23:27,869] Trial 5 finished with value: 0.7373427514055849 and parameters: {'n_estimators': 7019, 'learning_rate': 0.00846914204763431, 'max_depth': 4, 'min_child_weight': 1, 'gamma': 3.010731458174607, 'subsample': 0.7206896037372175, 'colsample_bytree': 0.56371807657503, 'reg_alpha': 0.027027732652652573, 'reg_lambda': 0.004360095434722283}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 10:26:42,910] Trial 6 finished with value: 0.7168758195689813 and parameters: {'n_estimators': 2399, 'learning_rate': 6.860168671953205e-06, 'max_depth': 3, 'min_child_weight': 3, 'gamma': 2.7537534463234827, 'subsample': 0.5734894873621003, 'colsample_bytree': 0.7733145333923592, 'reg_alpha': 1.1885777075877145e-06, 'reg_lambda': 0.0001533460782518407}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 10:42:43,206] Trial 7 finished with value: 0.7060261766347332 and parameters: {'n_estimators': 5744, 'learning_rate': 0.03957236342350058, 'max_depth': 10, 'min_child_weight': 6, 'gamma': 0.19844339510718068, 'subsample': 0.9952261365707072, 'colsample_bytree': 0.672875158563784, 'reg_alpha': 0.0001314992442164639, 'reg_lambda': 0.0011156446535019488}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 10:50:20,258] Trial 8 finished with value: 0.7285300469474558 and parameters: {'n_estimators': 3379, 'learning_rate': 1.3299865751893623e-05, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 0.6950637669599646, 'subsample': 0.9138902948983838, 'colsample_bytree': 0.9163870321251951, 'reg_alpha': 0.012018192720132834, 'reg_lambda': 0.0006968773076664206}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 11:17:01,963] Trial 9 finished with value: 0.7298167476907702 and parameters: {'n_estimators': 7995, 'learning_rate': 0.004183270897602411, 'max_depth': 9, 'min_child_weight': 1, 'gamma': 0.7908967242813303, 'subsample': 0.9450760151511923, 'colsample_bytree': 0.9019697066747521, 'reg_alpha': 0.002274741022165072, 'reg_lambda': 1.9327618006571702e-05}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 11:22:13,678] Trial 10 finished with value: 0.7337066679549085 and parameters: {'n_estimators': 6308, 'learning_rate': 0.060710469290096984, 'max_depth': 1, 'min_child_weight': 1, 'gamma': 1.96708697349953, 'subsample': 0.7999614764676884, 'colsample_bytree': 0.5106025930212308, 'reg_alpha': 6.590216960585068, 'reg_lambda': 0.04062871514161963}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 11:56:03,614] Trial 11 finished with value: 0.7352821914786394 and parameters: {'n_estimators': 6652, 'learning_rate': 0.001445922356923648, 'max_depth': 15, 'min_child_weight': 10, 'gamma': 4.843993248659162, 'subsample': 0.7099005204465435, 'colsample_bytree': 0.6044631835610546, 'reg_alpha': 0.06747185555827973, 'reg_lambda': 0.027549597871845747}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 12:23:24,683] Trial 12 finished with value: 0.7357621201676038 and parameters: {'n_estimators': 4388, 'learning_rate': 0.0009724286587723882, 'max_depth': 15, 'min_child_weight': 8, 'gamma': 4.976455243303998, 'subsample': 0.7230310298267222, 'colsample_bytree': 0.8317202618740276, 'reg_alpha': 0.001134536479096395, 'reg_lambda': 1.683672238342542e-06}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 13:12:36,099] Trial 13 finished with value: 0.7342367112774074 and parameters: {'n_estimators': 6892, 'learning_rate': 1.610155413240067e-06, 'max_depth': 13, 'min_child_weight': 8, 'gamma': 2.0061044716821437, 'subsample': 0.653620433431409, 'colsample_bytree': 0.9997772994302945, 'reg_alpha': 0.0474266063201727, 'reg_lambda': 0.0234538244644795}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 13:19:46,029] Trial 14 finished with value: 0.7372600555967292 and parameters: {'n_estimators': 4537, 'learning_rate': 0.010596830299044879, 'max_depth': 5, 'min_child_weight': 7, 'gamma': 3.9249863409587076, 'subsample': 0.8051512421965688, 'colsample_bytree': 0.5845648086003463, 'reg_alpha': 0.21474634065418877, 'reg_lambda': 0.4068334074055877}. Best is trial 5 with value: 0.7373427514055849.\n",
      "[I 2025-02-15 13:26:06,181] Trial 15 finished with value: 0.7379038615559639 and parameters: {'n_estimators': 4499, 'learning_rate': 0.011028893946108674, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 3.3567427390142726, 'subsample': 0.8308282108569828, 'colsample_bytree': 0.5808709691304476, 'reg_alpha': 0.20151511411925, 'reg_lambda': 0.5366119835327917}. Best is trial 15 with value: 0.7379038615559639.\n",
      "[I 2025-02-15 13:30:01,964] Trial 16 finished with value: 0.7373797245833604 and parameters: {'n_estimators': 3750, 'learning_rate': 0.012291434803164362, 'max_depth': 2, 'min_child_weight': 10, 'gamma': 3.2090253864143587, 'subsample': 0.8625083125496891, 'colsample_bytree': 0.5671664394263831, 'reg_alpha': 3.686262658063168, 'reg_lambda': 0.39491416532574247}. Best is trial 15 with value: 0.7379038615559639.\n",
      "[I 2025-02-15 13:33:02,282] Trial 17 finished with value: 0.7326816847523188 and parameters: {'n_estimators': 3510, 'learning_rate': 0.020828042077110018, 'max_depth': 1, 'min_child_weight': 10, 'gamma': 2.1979264993774352, 'subsample': 0.838689027593878, 'colsample_bytree': 0.6946564423716702, 'reg_alpha': 9.458433953958865, 'reg_lambda': 0.5460750718350863}. Best is trial 15 with value: 0.7379038615559639.\n",
      "[I 2025-02-15 13:38:04,174] Trial 18 finished with value: 0.7370142860891917 and parameters: {'n_estimators': 3479, 'learning_rate': 0.002603997684106083, 'max_depth': 4, 'min_child_weight': 9, 'gamma': 3.498317911225662, 'subsample': 0.8677496831043675, 'colsample_bytree': 0.6306692450672895, 'reg_alpha': 0.7508115198481363, 'reg_lambda': 0.4734792083830373}. Best is trial 15 with value: 0.7379038615559639.\n",
      "[I 2025-02-15 13:42:00,868] Trial 19 finished with value: 0.719883517934853 and parameters: {'n_estimators': 4213, 'learning_rate': 0.0005120229415346459, 'max_depth': 2, 'min_child_weight': 6, 'gamma': 1.3135161362692553, 'subsample': 0.8737850260671025, 'colsample_bytree': 0.5457962866310712, 'reg_alpha': 1.30842505882184, 'reg_lambda': 0.15271289361854123}. Best is trial 15 with value: 0.7379038615559639.\n",
      "[I 2025-02-15 13:48:33,102] Trial 20 finished with value: 0.7337971428105927 and parameters: {'n_estimators': 5151, 'learning_rate': 0.0967403526087386, 'max_depth': 3, 'min_child_weight': 7, 'gamma': 2.5849029703380504, 'subsample': 0.7702874903363511, 'colsample_bytree': 0.7294646062727383, 'reg_alpha': 0.28075021237414277, 'reg_lambda': 9.784729597650749}. Best is trial 15 with value: 0.7379038615559639.\n",
      "[I 2025-02-15 13:53:04,212] Trial 21 finished with value: 0.7379158312187555 and parameters: {'n_estimators': 2861, 'learning_rate': 0.007970837724134367, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 3.119949581955642, 'subsample': 0.7423825131770212, 'colsample_bytree': 0.5679354275330923, 'reg_alpha': 0.015968693241331076, 'reg_lambda': 0.006878748379075993}. Best is trial 21 with value: 0.7379158312187555.\n",
      "[I 2025-02-15 13:57:41,496] Trial 22 finished with value: 0.7379546859781623 and parameters: {'n_estimators': 2717, 'learning_rate': 0.011061644230637697, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 3.3096409895054855, 'subsample': 0.8870073463319801, 'colsample_bytree': 0.5049221703175945, 'reg_alpha': 3.9960092400982936, 'reg_lambda': 1.5017883088044244}. Best is trial 22 with value: 0.7379546859781623.\n",
      "[I 2025-02-15 14:03:07,884] Trial 23 finished with value: 0.7379420371295564 and parameters: {'n_estimators': 2722, 'learning_rate': 0.004118063060396655, 'max_depth': 7, 'min_child_weight': 2, 'gamma': 4.34917132683362, 'subsample': 0.7706845352252016, 'colsample_bytree': 0.5009765373373624, 'reg_alpha': 0.1786050928517559, 'reg_lambda': 1.5693173453767875}. Best is trial 22 with value: 0.7379546859781623.\n",
      "[I 2025-02-15 14:08:41,758] Trial 24 finished with value: 0.737872319890327 and parameters: {'n_estimators': 2778, 'learning_rate': 0.0035029334829240096, 'max_depth': 7, 'min_child_weight': 2, 'gamma': 4.338769428516008, 'subsample': 0.7628674996378351, 'colsample_bytree': 0.5029909690502942, 'reg_alpha': 0.00040631382169355933, 'reg_lambda': 1.4331981443532116}. Best is trial 22 with value: 0.7379546859781623.\n",
      "[I 2025-02-15 14:13:33,500] Trial 25 finished with value: 0.7350623188918448 and parameters: {'n_estimators': 2843, 'learning_rate': 0.02551550789576693, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 4.25316176790829, 'subsample': 0.6755568447669174, 'colsample_bytree': 0.5051515600084828, 'reg_alpha': 0.009906869526320857, 'reg_lambda': 0.08900388498355219}. Best is trial 22 with value: 0.7379546859781623.\n",
      "[I 2025-02-15 14:20:55,226] Trial 26 finished with value: 0.7366795304065052 and parameters: {'n_estimators': 2937, 'learning_rate': 0.001167203250172527, 'max_depth': 8, 'min_child_weight': 2, 'gamma': 3.7214838727825352, 'subsample': 0.9064829249735278, 'colsample_bytree': 0.6443060116883245, 'reg_alpha': 2.059008148181508, 'reg_lambda': 1.8686462344031594}. Best is trial 22 with value: 0.7379546859781623.\n",
      "[I 2025-02-15 14:25:23,520] Trial 27 finished with value: 0.738038980045497 and parameters: {'n_estimators': 2486, 'learning_rate': 0.004939215455918097, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 4.639337739841748, 'subsample': 0.7901722348670108, 'colsample_bytree': 0.6146245639718776, 'reg_alpha': 0.38827607614837994, 'reg_lambda': 0.006865086581289021}. Best is trial 27 with value: 0.738038980045497.\n",
      "[I 2025-02-15 14:30:14,435] Trial 28 finished with value: 0.7376662639963514 and parameters: {'n_estimators': 2325, 'learning_rate': 0.002814179460181346, 'max_depth': 7, 'min_child_weight': 4, 'gamma': 4.649266223284539, 'subsample': 0.8009421601114317, 'colsample_bytree': 0.6084476626580508, 'reg_alpha': 0.3171516349406394, 'reg_lambda': 0.011652671001970741}. Best is trial 27 with value: 0.738038980045497.\n",
      "[I 2025-02-15 14:35:21,184] Trial 29 finished with value: 0.7313310655161038 and parameters: {'n_estimators': 2172, 'learning_rate': 0.00017864228354512693, 'max_depth': 8, 'min_child_weight': 5, 'gamma': 4.702213830669928, 'subsample': 0.5810780572533499, 'colsample_bytree': 0.5313000520040048, 'reg_alpha': 0.10597775877871438, 'reg_lambda': 2.4717502163325205}. Best is trial 27 with value: 0.738038980045497.\n",
      "[W 2025-02-15 14:35:25,356] Trial 30 failed with parameters: {'n_estimators': 2065, 'learning_rate': 0.0006009253376787746, 'max_depth': 6, 'min_child_weight': 3, 'gamma': 4.398922241909358, 'subsample': 0.9057200100409235, 'colsample_bytree': 0.6694618287060283, 'reg_alpha': 0.6188973224583509, 'reg_lambda': 0.13961737134194485} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\juneh\\AppData\\Local\\Temp\\ipykernel_2536\\365773763.py\", line 27, in objective\n",
      "    model.fit(Total_X_train, Total_y_train, eval_set=[(Total_X_test, Total_y_test)], verbose=False)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py\", line 1411, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\core.py\", line 1780, in update\n",
      "    dtrain.handle))\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-15 14:35:25,439] Trial 30 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2536\\365773763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Optuna 스터디 생성 및 최적화 실행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# 최적의 하이퍼파라미터 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m         )\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             )\n\u001b[0;32m     74\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     ):\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2536\\365773763.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTotal_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTotal_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTotal_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTotal_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0my_pred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTotal_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1409\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1412\u001b[0m         )\n\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1778\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1779\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1780\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1781\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1782\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 목적 함수 정의\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 2000, 8000),  # 기본값: 100\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1e-1, log=True),  # 기본값: 0.3\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),  # 기본값: 6\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # 기본값: 1\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),  # 기본값: 0\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # 기본값: 1\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # 기본값: 1\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-6, 10.0, log=True),  # 기본값: 0\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-6, 10.0, log=True),  # 기본값: 1\n",
    "        \n",
    "        'random_state': 42,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'use_label_encoder': False,\n",
    "        'verbosity': 0,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**param)\n",
    "    model.fit(Total_X_train, Total_y_train, eval_set=[(Total_X_test, Total_y_test)], verbose=False)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(Total_X_test)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(Total_y_test, y_pred_proba)\n",
    "    return auc\n",
    "\n",
    "# Optuna 스터디 생성 및 최적화 실행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1200)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
