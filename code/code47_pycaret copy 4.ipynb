{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 난임 환자 대상 임신 성공 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGAimers 6th 온라인 해커톤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy scikit-learn matplotlib pycaret lightgbm xgboost catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "Total_train = pd.read_csv('../data/Total_train_dataset_47.csv')\n",
    "Total_test = pd.read_csv('../data/Total_test_dataset_47.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 열을 제외한 특성과 타겟 변수 분리\n",
    "Total_X = Total_train.drop(['임신_성공_여부', 'ID'], axis=1)\n",
    "Total_y = Total_train['임신_성공_여부']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 로드\n",
    "Total_train = pd.read_csv('../data/Total_train_dataset_47.csv')\n",
    "\n",
    "# ID 열을 제외한 특성과 타겟 변수 분리\n",
    "Total_X = Total_train.drop(['임신_성공_여부', 'ID'], axis=1)\n",
    "Total_y = Total_train['임신_성공_여부']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_categorical_columns = [\n",
    "    \"시술_당시_나이\",\n",
    "    \"난자_기증자_나이\",\n",
    "    \"정자_기증자_나이\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 범주형 변수를 문자열로 변환\n",
    "Total_X[Total_categorical_columns] = Total_X[Total_categorical_columns].astype(str)\n",
    "Total_test[Total_categorical_columns] = Total_test[Total_categorical_columns].astype(str)\n",
    "\n",
    "# OrdinalEncoder를 사용하여 범주형 변수 인코딩\n",
    "Total_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "Total_X[Total_categorical_columns] = Total_encoder.fit_transform(Total_X[Total_categorical_columns])\n",
    "Total_test[Total_categorical_columns] = Total_encoder.transform(Total_test[Total_categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "\n",
    "# 특성 이름의 공백을 밑줄로 대체\n",
    "Total_X.columns = Total_X.columns.str.replace(' ', '_')\n",
    "Total_test.columns = Total_test.columns.str.replace(' ', '_')\n",
    "\n",
    "# 데이터 분할\n",
    "Total_X_train, Total_X_test, Total_y_train, Total_y_test = train_test_split(Total_X,\n",
    "                                                                            Total_y,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42,\n",
    "                                                                            stratify=Total_y)\n",
    "\n",
    "# # PyCaret 설정\n",
    "# clf = setup(data=pd.concat([Total_X_train, Total_y_train], axis=1), \n",
    "#             target='임신_성공_여부', \n",
    "#             session_id=42, \n",
    "#             fix_imbalance=True, \n",
    "#             normalize=True, \n",
    "#             feature_selection=True)\n",
    "\n",
    "# # 모델 비교 및 최상의 모델 선택\n",
    "# best_model = compare_models(n_select=5, sort='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최상의 모델 하이퍼파라미터 튜닝\n",
    "# tuned_models = [tune_model(model, optimize='AUC') for model in best_model]\n",
    "\n",
    "# # 메타 모델 리스트\n",
    "# meta_models = [\n",
    "#     LogisticRegression(),\n",
    "#     RandomForestClassifier(random_state=42),\n",
    "#     LGBMClassifier(random_state=42)\n",
    "# ]\n",
    "\n",
    "# # 메타 모델 성능 저장을 위한 리스트\n",
    "# meta_model_performance = []\n",
    "\n",
    "# # 여러 메타 모델로 스태킹 앙상블 수행 및 성능 평가\n",
    "# for meta_model in meta_models:\n",
    "#     stacked_model = stack_models(estimator_list=tuned_models, meta_model=meta_model, fold=5)\n",
    "#     final_model = finalize_model(stacked_model)\n",
    "#     y_pred = predict_model(final_model, data=Total_X_test)\n",
    "    \n",
    "#     accuracy = accuracy_score(Total_y_test, y_pred['Label'])\n",
    "#     f1 = f1_score(Total_y_test, y_pred['Label'])\n",
    "#     auc = roc_auc_score(Total_y_test, y_pred['Score'])\n",
    "    \n",
    "#     meta_model_performance.append((meta_model, accuracy, f1, auc))\n",
    "\n",
    "#     print(f\"Meta Model: {meta_model.__class__.__name__}\")\n",
    "#     print(f\"Accuracy: {accuracy}\")\n",
    "#     print(f\"F1 Score: {f1}\")\n",
    "#     print(f\"AUC: {auc}\")\n",
    "#     print(\"---\")\n",
    "\n",
    "# # 최상의 메타 모델 선택\n",
    "# best_meta_model = max(meta_model_performance, key=lambda x: x[3])[0]  # AUC 기준으로 선택\n",
    "\n",
    "# print(f\"Best Meta Model: {best_meta_model.__class__.__name__}\")\n",
    "\n",
    "# # 최상의 메타 모델로 최종 모델 학습\n",
    "# final_stacked_model = stack_models(estimator_list=tuned_models, meta_model=best_meta_model, fold=5)\n",
    "# final_model = finalize_model(final_stacked_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모든 학습 데이터를 사용하여 최종 모델 학습\n",
    "# final_model.fit(Total_X, Total_y)\n",
    "\n",
    "# # 테스트 데이터 예측\n",
    "# Total_pred_scores = final_model.decision_function(Total_test.drop('ID', axis=1))\n",
    "\n",
    "# # 예측 점수를 테스트 데이터에 추가\n",
    "# Total_test['probability'] = Total_pred_scores\n",
    "\n",
    "# # 최종 제출 파일 생성\n",
    "# submission = Total_test[['ID', 'probability']]\n",
    "# submission = submission.sort_values(by='ID')\n",
    "\n",
    "# # 제출 파일 저장\n",
    "# submission.to_csv('../submission/code47_all_final_model.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250222_013301\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       9.25 GB / 15.86 GB (58.3%)\n",
      "Disk Space Avail:   191.43 GB / 476.30 GB (40.2%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 5400s of the 21600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-02-22 10:33:07,707\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250222_013301\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Beginning AutoGluon training ... Time limit = 5391s\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250222_013301\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Train Data Rows:    227861\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Train Data Columns: 94\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Label Column:       임신_성공_여부\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tAvailable Memory:                    8726.96 MB\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tTrain Data (Original)  Memory Usage: 163.41 MB (1.9% of available memory)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t\tNote: Converting 52 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tUnused Original Features (Count: 6): ['불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_ICI', '특정_시술_유형_IUI', '특정_시술_유형_IVI', '난자채취_적정기간']\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t('int', []) : 6 | ['불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_ICI', '특정_시술_유형_IUI', '특정_시술_유형_IVI', ...]\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t('float', []) : 42 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t('int', [])   : 46 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t('float', [])     : 32 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '총_생성_배아_수', '미세주입된_난자_수', '미세주입에서_생성된_배아_수', ...]\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t('int', [])       : 10 | ['총_시술_횟수', '클리닉_내_총_시술_횟수', 'IVF_시술_횟수', 'DI_시술_횟수', '총_임신_횟수', ...]\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t('int', ['bool']) : 46 | ['배란_자극_여부', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', '남성_주_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t1.8s = Fit runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t88 features in original data used to generate 88 features in processed data.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tTrain Data (Processed) Memory Usage: 83.01 MB (1.0% of available memory)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Data preprocessing and feature engineering runtime = 1.96s ...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 3591.62s of the 5388.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.6533\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t46.2s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 3541.61s of the 5338.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.6375\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.29s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t43.8s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 3497.23s of the 5294.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.27%)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7393\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t35.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.52s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 3459.07s of the 5256.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.49%)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7392\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t32.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3424.14s of the 5221.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7264\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t37.26s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t12.66s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3373.55s of the 5170.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7272\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t39.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t14.87s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 3318.50s of the 5115.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.06%)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7395\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t175.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3140.33s of the 4937.48s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7287\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t35.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t12.54s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 3091.45s of the 4888.60s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7287\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t37.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t12.82s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3040.46s of the 4837.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.33% memory usage per fold, 45.32%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=11.33%)\n",
      "\u001b[36m(_ray_fit pid=20592)\u001b[0m No improvement since epoch 8: early stopping\n",
      "\u001b[36m(_ray_fit pid=19480)\u001b[0m No improvement since epoch 8: early stopping\n",
      "\u001b[36m(_ray_fit pid=16376)\u001b[0m No improvement since epoch 6: early stopping\n",
      "\u001b[36m(_ray_fit pid=1336)\u001b[0m No improvement since epoch 9: early stopping\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7369\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t1227.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t2.14s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 1809.88s of the 3607.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.81%)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7389\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t148.34s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.91s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1658.77s of the 3455.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=5.82%)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4144, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4144, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1653.72s of the 3450.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.16%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +33m9s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[33m(autoscaler +33m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7381\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t40.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.55s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1610.96s of the 3408.11s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.68%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +33m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +34m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +34m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7394\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t122.37s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1485.97s of the 3283.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=5.84%)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=19780, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=19780, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1481.04s of the 3278.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.72%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +35m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[36m(_ray_fit pid=11124)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.487482\n",
      "\u001b[33m(autoscaler +36m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7393\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t64.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t1.61s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1413.84s of the 3210.99s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.65% memory usage per fold, 42.58%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=10.65%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +36m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +37m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +37m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +38m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=21296)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +38m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +39m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +40m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +40m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +41m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=11352)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +41m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +42m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +43m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +43m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=21496)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +44m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +44m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +45m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +45m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=18076)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +46m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +47m10s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +47m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +48m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=9620)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +48m55s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +49m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +50m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +50m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1944)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +51m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +51m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +52m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +53m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6460)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +53m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=21348)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 15)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7361\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t1163.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t2.94s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 247.50s of the 2044.65s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.19%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +56m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=9176)\u001b[0m \tRan out of time, early stopping on iteration 280.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +56m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=16796)\u001b[0m \tRan out of time, early stopping on iteration 277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +57m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=19380)\u001b[0m \tRan out of time, early stopping on iteration 269.\n",
      "\u001b[36m(_ray_fit pid=640)\u001b[0m \tRan out of time, early stopping on iteration 287.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +57m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=11432)\u001b[0m \tRan out of time, early stopping on iteration 288.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +58m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1116)\u001b[0m \tRan out of time, early stopping on iteration 273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +59m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4312)\u001b[0m \tRan out of time, early stopping on iteration 281.\n",
      "\u001b[36m(_ray_fit pid=2236)\u001b[0m \tRan out of time, early stopping on iteration 274.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7392\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t213.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 31.24s of the 1828.40s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.51%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +59m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=9416)\u001b[0m \tRan out of time, early stopping on iteration 394. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=9416)\u001b[0m \t[394]\tvalid_set's binary_logloss: 0.490189\n",
      "\u001b[36m(_ray_fit pid=20692)\u001b[0m \tRan out of time, early stopping on iteration 422. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=20692)\u001b[0m \t[422]\tvalid_set's binary_logloss: 0.488604\n",
      "\u001b[36m(_ray_fit pid=4440)\u001b[0m \tRan out of time, early stopping on iteration 428. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=4440)\u001b[0m \t[428]\tvalid_set's binary_logloss: 0.490545\n",
      "\u001b[36m(_ray_fit pid=20564)\u001b[0m \tRan out of time, early stopping on iteration 424. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=20564)\u001b[0m \t[424]\tvalid_set's binary_logloss: 0.489709\n",
      "\u001b[36m(_ray_fit pid=10384)\u001b[0m \tRan out of time, early stopping on iteration 417. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=10384)\u001b[0m \t[417]\tvalid_set's binary_logloss: 0.48875\n",
      "\u001b[36m(_ray_fit pid=17480)\u001b[0m \tRan out of time, early stopping on iteration 421. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=17480)\u001b[0m \t[421]\tvalid_set's binary_logloss: 0.488757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=11548)\u001b[0m \tRan out of time, early stopping on iteration 402. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=11548)\u001b[0m \t[402]\tvalid_set's binary_logloss: 0.491373\n",
      "\u001b[36m(_ray_fit pid=20748)\u001b[0m \tRan out of time, early stopping on iteration 437. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=20748)\u001b[0m \t[437]\tvalid_set's binary_logloss: 0.488384\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7376\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t42.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.92s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1782.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.208, 'CatBoost_BAG_L1': 0.208, 'NeuralNetFastAI_BAG_L1': 0.125, 'XGBoost_BAG_L1': 0.125, 'CatBoost_r177_BAG_L1': 0.125, 'LightGBM_r131_BAG_L1': 0.125, 'LightGBM_BAG_L1': 0.042, 'NeuralNetFastAI_r191_BAG_L1': 0.042}\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.74\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t12.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.04s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1769.52s of the 1769.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.72%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7398\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t36.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 1729.80s of the 1729.73s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.73%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h1m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7399\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t35.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 1691.44s of the 1691.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7439\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t50.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t14.97s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 1625.26s of the 1625.18s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7446\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t60.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t15.2s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 1548.83s of the 1548.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.73%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h4m23s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h4m58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h5m33s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7399\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t126.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 1419.46s of the 1419.38s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7481\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t39.05s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t14.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 1365.26s of the 1365.19s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7475\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t41.23s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t14.59s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1308.64s of the 1308.56s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.76% memory usage per fold, 55.04%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=13.76%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h8m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h8m55s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h9m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h10m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=13128)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h10m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h11m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h11m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h12m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h13m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h13m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h14m10s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h14m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2104)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 24)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h15m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h15m55s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h16m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=13124)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h17m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h17m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h18m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h18m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=17956)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h19m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h20m1s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h20m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h21m11s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h21m46s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h22m21s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h22m56s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h23m31s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=6280)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 23)\n",
      "\u001b[36m(_ray_fit pid=9876)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7392\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t1043.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t2.21s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: XGBoost_BAG_L2 ... Training model for up to 261.57s of the 261.50s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.69% memory usage per fold, 42.75%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=10.69%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h25m46s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h26m21s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h26m56s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[33m(autoscaler +1h27m31s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7398\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t161.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t1.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 97.39s of the 97.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.46%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h28m31s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=18772, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=18772, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 92.03s of the 91.95s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.81%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h29m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7406\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t59.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.71s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 30.61s of the 30.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.17%)\n",
      "\u001b[36m(_ray_fit pid=18772)\u001b[0m \tRan out of time, early stopping on iteration 64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(autoscaler +1h29m41s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 16.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2396)\u001b[0m \tRan out of time, early stopping on iteration 61.\n",
      "\u001b[36m(_ray_fit pid=16472)\u001b[0m \tRan out of time, early stopping on iteration 61.\n",
      "\u001b[36m(_ray_fit pid=15492)\u001b[0m \tRan out of time, early stopping on iteration 62.\n",
      "\u001b[36m(_ray_fit pid=8316)\u001b[0m \tRan out of time, early stopping on iteration 60.\n",
      "\u001b[36m(_ray_fit pid=3156)\u001b[0m \tRan out of time, early stopping on iteration 64.\n",
      "\u001b[36m(_ray_fit pid=3896)\u001b[0m \tRan out of time, early stopping on iteration 61.\n",
      "\u001b[36m(_ray_fit pid=14700)\u001b[0m \tRan out of time, early stopping on iteration 63.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7394\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t39.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -12.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.421, 'ExtraTreesEntr_BAG_L2': 0.316, 'RandomForestEntr_BAG_L2': 0.158, 'RandomForestGini_BAG_L2': 0.105}\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.7494\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t20.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m AutoGluon training complete, total runtime = 5424.2s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 802.0 rows/s (28483 batch size)\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250222_013301\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=18784)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                          model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           WeightedEnsemble_L2       0.739599   0.740038     roc_auc       11.899191       8.652270  2982.118069                 0.016253                0.035942          12.863322            2       True         18\n",
      "1             LightGBMXT_BAG_L2       0.739593   0.739785     roc_auc       27.582592     153.528866  3453.394909                 0.533658                0.377523          36.812025            2       True         19\n",
      "2               CatBoost_BAG_L2       0.739545   0.739850     roc_auc       27.210961     153.234503  3543.115410                 0.162028                0.083159         126.532526            2       True         23\n",
      "3        NeuralNetFastAI_BAG_L2       0.739506   0.739167     roc_auc       29.788249     155.357018  4460.409090                 2.739316                2.205674        1043.826206            2       True         26\n",
      "4               LightGBM_BAG_L2       0.739369   0.739885     roc_auc       27.597678     153.506487  3452.032398                 0.548745                0.355144          35.449514            2       True         20\n",
      "5          CatBoost_r177_BAG_L2       0.739343   0.739399     roc_auc       27.226179     153.221360  3456.484594                 0.177246                0.070017          39.901710            2       True         29\n",
      "6          CatBoost_r177_BAG_L1       0.739271   0.739373     roc_auc        0.184590       0.050826   122.372307                 0.184590                0.050826         122.372307            1       True         13\n",
      "7             LightGBMXT_BAG_L1       0.739207   0.739341     roc_auc        0.739973       0.515741    35.380538                 0.739973                0.515741          35.380538            1       True          3\n",
      "8               CatBoost_BAG_L1       0.739143   0.739463     roc_auc        0.567882       0.104048   175.357486                 0.567882                0.104048         175.357486            1       True          7\n",
      "9                XGBoost_BAG_L2       0.739073   0.739822     roc_auc       28.312370     154.184095  3577.716763                 1.263436                1.032752         161.133879            2       True         27\n",
      "10           CatBoost_r9_BAG_L1       0.739039   0.739218     roc_auc        0.350272       0.169084   213.505396                 0.350272                0.169084         213.505396            1       True         16\n",
      "11       NeuralNetFastAI_BAG_L1       0.739018   0.736912     roc_auc        3.122821       2.140203  1227.580294                 3.122821                2.140203        1227.580294            1       True         10\n",
      "12         LightGBMLarge_BAG_L2       0.739013   0.740615     roc_auc       28.100385     153.858095  3475.643774                 1.051452                0.706752          59.060890            2       True         28\n",
      "13         LightGBM_r131_BAG_L1       0.738818   0.739259     roc_auc        1.969602       1.608903    64.729573                 1.969602                1.608903          64.729573            1       True         14\n",
      "14               XGBoost_BAG_L1       0.738733   0.738894     roc_auc        1.427565       0.908129   148.344696                 1.427565                0.908129         148.344696            1       True         11\n",
      "15  NeuralNetFastAI_r191_BAG_L1       0.738719   0.736149     roc_auc        3.329425       2.939724  1163.232518                 3.329425                2.939724        1163.232518            1       True         15\n",
      "16         LightGBMLarge_BAG_L1       0.738653   0.738120     roc_auc        0.813709       0.551737    40.451270                 0.813709                0.551737          40.451270            1       True         12\n",
      "17              LightGBM_BAG_L1       0.738603   0.739184     roc_auc        0.541082       0.348754    32.257335                 0.541082                0.348754          32.257335            1       True          4\n",
      "18        ExtraTreesEntr_BAG_L2       0.737048   0.747478     roc_auc       27.785411     167.746300  3457.815039                 0.736477               14.594957          41.232155            2       True         25\n",
      "19          WeightedEnsemble_L3       0.737021   0.749432     roc_auc       30.113941     212.304244  3628.584178                 0.000000                0.031262          20.926681            3       True         30\n",
      "20          LightGBM_r96_BAG_L1       0.736954   0.737583     roc_auc        1.002977       0.921719    42.930598                 1.002977                0.921719          42.930598            1       True         17\n",
      "21        ExtraTreesGini_BAG_L2       0.736296   0.748081     roc_auc       27.777986     167.503917  3455.628585                 0.729052               14.352574          39.045701            2       True         24\n",
      "22      RandomForestEntr_BAG_L2       0.734983   0.744552     roc_auc       27.843583     168.352717  3476.983090                 0.794649               15.201374          60.400206            2       True         22\n",
      "23      RandomForestGini_BAG_L2       0.733314   0.743932     roc_auc       27.853762     168.124077  3466.979436                 0.804829               14.972733          50.396552            2       True         21\n",
      "24        ExtraTreesEntr_BAG_L1       0.730628   0.728691     roc_auc        0.719912      12.820319    37.503007                 0.719912               12.820319          37.503007            1       True          9\n",
      "25        ExtraTreesGini_BAG_L1       0.730130   0.728692     roc_auc        0.677463      12.537252    35.680175                 0.677463               12.537252          35.680175            1       True          8\n",
      "26      RandomForestEntr_BAG_L1       0.730101   0.727239     roc_auc        0.727184      14.871891    39.434947                 0.727184               14.871891          39.434947            1       True          6\n",
      "27      RandomForestGini_BAG_L1       0.728714   0.726424     roc_auc        0.752302      12.664548    37.256455                 0.752302               12.664548          37.256455            1       True          5\n",
      "28        KNeighborsUnif_BAG_L1       0.656509   0.653345     roc_auc        4.790152      46.195489     0.280034                 4.790152               46.195489           0.280034            1       True          1\n",
      "29        KNeighborsDist_BAG_L1       0.639953   0.637486     roc_auc        5.332023      43.802976     0.286256                 5.332023               43.802976           0.286256            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t5478s\t = DyStack   runtime |\t16122s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 16122s\n",
      "AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250222_013301\"\n",
      "Train Data Rows:    256344\n",
      "Train Data Columns: 94\n",
      "Label Column:       임신_성공_여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7747.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 183.84 MB (2.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 52 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 5): ['불임_원인_-_정자_면역학적_요인', '불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_IVI', '난자채취_적정기간']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['불임_원인_-_정자_면역학적_요인', '불임_원인_-_정자_형태', '특정_시술_유형_GenericDI', '특정_시술_유형_IVI', '난자채취_적정기간']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\t\t('int', [])   : 47 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 32 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '총_생성_배아_수', '미세주입된_난자_수', '미세주입에서_생성된_배아_수', ...]\n",
      "\t\t('int', [])       : 10 | ['총_시술_횟수', '클리닉_내_총_시술_횟수', 'IVF_시술_횟수', 'DI_시술_횟수', '총_임신_횟수', ...]\n",
      "\t\t('int', ['bool']) : 47 | ['배란_자극_여부', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', '남성_주_불임_원인', ...]\n",
      "\t1.7s = Fit runtime\n",
      "\t89 features in original data used to generate 89 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 93.63 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 16120.08s of the 16120.07s of remaining time.\n",
      "\t0.6545\t = Validation score   (roc_auc)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t68.17s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 16048.67s of the 16048.66s of remaining time.\n",
      "\t0.6389\t = Validation score   (roc_auc)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t68.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 15979.93s of the 15979.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.17%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t37.34s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 15939.76s of the 15939.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.33%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t35.43s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 15901.53s of the 15901.51s of remaining time.\n",
      "\t0.7279\t = Validation score   (roc_auc)\n",
      "\t42.37s\t = Training   runtime\n",
      "\t13.18s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 15845.25s of the 15845.23s of remaining time.\n",
      "\t0.7291\t = Validation score   (roc_auc)\n",
      "\t44.6s\t = Training   runtime\n",
      "\t13.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 15786.53s of the 15786.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.94%)\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t197.93s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 15585.86s of the 15585.84s of remaining time.\n",
      "\t0.73\t = Validation score   (roc_auc)\n",
      "\t41.33s\t = Training   runtime\n",
      "\t13.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 15530.79s of the 15530.77s of remaining time.\n",
      "\t0.7304\t = Validation score   (roc_auc)\n",
      "\t42.92s\t = Training   runtime\n",
      "\t13.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 15473.76s of the 15473.74s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.76% memory usage per fold, 51.04%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.76%)\n",
      "\t0.7374\t = Validation score   (roc_auc)\n",
      "\t866.66s\t = Training   runtime\n",
      "\t1.62s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 14604.05s of the 14604.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=9.87%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t175.39s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 14425.71s of the 14425.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.80%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21436, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21436, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 14420.51s of the 14420.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.89%)\n",
      "\t0.7382\t = Validation score   (roc_auc)\n",
      "\t44.6s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 14373.56s of the 14373.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.40%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t140.42s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 14230.40s of the 14230.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.50%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4100, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4100, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 14225.22s of the 14225.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.48%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t74.11s\t = Training   runtime\n",
      "\t1.96s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 14148.61s of the 14148.60s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.02% memory usage per fold, 48.09%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.02%)\n",
      "\t0.736\t = Validation score   (roc_auc)\n",
      "\t2309.72s\t = Training   runtime\n",
      "\t3.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 11835.50s of the 11835.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.77%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t380.37s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 11452.35s of the 11452.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.24%)\n",
      "\t0.7396\t = Validation score   (roc_auc)\n",
      "\t137.18s\t = Training   runtime\n",
      "\t3.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 11311.97s of the 11311.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.54%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=16364, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=16364, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 11306.78s of the 11306.77s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.51% memory usage per fold, 50.05%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.51%)\n",
      "\t0.7371\t = Validation score   (roc_auc)\n",
      "\t448.02s\t = Training   runtime\n",
      "\t2.09s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 10856.23s of the 10856.22s of remaining time.\n",
      "\t0.7189\t = Validation score   (roc_auc)\n",
      "\t210.93s\t = Training   runtime\n",
      "\t14.3s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 10630.20s of the 10630.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.84%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t278.5s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 10348.94s of the 10348.92s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.13% memory usage per fold, 48.54%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.13%)\n",
      "\t0.738\t = Validation score   (roc_auc)\n",
      "\t435.54s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 9910.46s of the 9910.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.81%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t435.45s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 9472.16s of the 9472.15s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 232 due to low memory. Expected memory usage reduced from 19.38% -> 15.0% of available memory...\n",
      "\t0.6973\t = Validation score   (roc_auc)\n",
      "\t199.1s\t = Training   runtime\n",
      "\t12.86s\t = Validation runtime\n",
      "Fitting model: LightGBM_r188_BAG_L1 ... Training model for up to 9259.13s of the 9259.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.03%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t48.8s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ... Training model for up to 9207.43s of the 9207.42s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.04% memory usage per fold, 48.17%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.04%)\n",
      "\t0.7355\t = Validation score   (roc_auc)\n",
      "\t2976.16s\t = Training   runtime\n",
      "\t4.62s\t = Validation runtime\n",
      "Fitting model: XGBoost_r89_BAG_L1 ... Training model for up to 6227.66s of the 6227.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=9.99%)\n",
      "\t0.7392\t = Validation score   (roc_auc)\n",
      "\t259.27s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r30_BAG_L1 ... Training model for up to 5965.44s of the 5965.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.94%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r30_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=9736, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=9736, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r130_BAG_L1 ... Training model for up to 5960.22s of the 5960.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.88%)\n",
      "\t0.7388\t = Validation score   (roc_auc)\n",
      "\t36.31s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r86_BAG_L1 ... Training model for up to 5921.61s of the 5921.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.50%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r86_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=3908, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=3908, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: CatBoost_r50_BAG_L1 ... Training model for up to 5916.48s of the 5916.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.38%)\n",
      "\t0.7393\t = Validation score   (roc_auc)\n",
      "\t142.93s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r11_BAG_L1 ... Training model for up to 5771.32s of the 5771.31s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.24% memory usage per fold, 48.94%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.24%)\n",
      "\t0.729\t = Validation score   (roc_auc)\n",
      "\t2793.96s\t = Training   runtime\n",
      "\t4.96s\t = Validation runtime\n",
      "Fitting model: XGBoost_r194_BAG_L1 ... Training model for up to 2973.78s of the 2973.77s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.67% memory usage per fold, 42.66%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=10.67%)\n",
      "\t0.7386\t = Validation score   (roc_auc)\n",
      "\t43.29s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r172_BAG_L1 ... Training model for up to 2927.59s of the 2927.57s of remaining time.\n",
      "\t0.7208\t = Validation score   (roc_auc)\n",
      "\t271.11s\t = Training   runtime\n",
      "\t13.74s\t = Validation runtime\n",
      "Fitting model: CatBoost_r69_BAG_L1 ... Training model for up to 2642.08s of the 2642.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.83%)\n",
      "\t0.7394\t = Validation score   (roc_auc)\n",
      "\t202.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r103_BAG_L1 ... Training model for up to 2436.72s of the 2436.70s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.29% memory usage per fold, 49.15%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.29%)\n",
      "\t0.7345\t = Validation score   (roc_auc)\n",
      "\t1338.58s\t = Training   runtime\n",
      "\t2.67s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r14_BAG_L1 ... Training model for up to 1094.93s of the 1094.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=6.80%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r14_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=716, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=716, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r161_BAG_L1 ... Training model for up to 1089.71s of the 1089.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.91%)\n",
      "\t0.7376\t = Validation score   (roc_auc)\n",
      "\t110.51s\t = Training   runtime\n",
      "\t2.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r143_BAG_L1 ... Training model for up to 976.53s of the 976.52s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.22% memory usage per fold, 48.87%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.22%)\n",
      "\t0.7378\t = Validation score   (roc_auc)\n",
      "\t776.26s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_r70_BAG_L1 ... Training model for up to 197.27s of the 197.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=7.97%)\n",
      "\t0.7395\t = Validation score   (roc_auc)\n",
      "\t173.6s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r156_BAG_L1 ... Training model for up to 20.79s of the 20.77s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.38% memory usage per fold, 49.52%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=12.38%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_r156_BAG_L1.\n",
      "Fitting model: LightGBM_r196_BAG_L1 ... Training model for up to 13.89s of the 13.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=16, gpus=0, memory=8.26%)\n",
      "\t0.7292\t = Validation score   (roc_auc)\n",
      "\t28.7s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1612.01s of the -17.52s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_r102_BAG_L1': 0.16, 'LightGBM_r96_BAG_L1': 0.12, 'LightGBMXT_BAG_L1': 0.08, 'CatBoost_BAG_L1': 0.08, 'XGBoost_BAG_L1': 0.08, 'CatBoost_r177_BAG_L1': 0.08, 'CatBoost_r137_BAG_L1': 0.08, 'LightGBM_r130_BAG_L1': 0.08, 'RandomForestEntr_BAG_L1': 0.04, 'NeuralNetFastAI_BAG_L1': 0.04, 'NeuralNetFastAI_r191_BAG_L1': 0.04, 'XGBoost_r89_BAG_L1': 0.04, 'CatBoost_r50_BAG_L1': 0.04, 'NeuralNetFastAI_r103_BAG_L1': 0.04}\n",
      "\t0.7402\t = Validation score   (roc_auc)\n",
      "\t31.56s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16171.23s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1877.6 rows/s (32043 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250222_013301\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          model  score_val eval_metric  pred_time_val  \\\n",
      "0           WeightedEnsemble_L2   0.740214     roc_auc      28.817124   \n",
      "1           LightGBM_r96_BAG_L1   0.739580     roc_auc       3.351468   \n",
      "2               CatBoost_BAG_L1   0.739558     roc_auc       0.081565   \n",
      "3           CatBoost_r13_BAG_L1   0.739540     roc_auc       0.066689   \n",
      "4          CatBoost_r177_BAG_L1   0.739495     roc_auc       0.057192   \n",
      "5           CatBoost_r70_BAG_L1   0.739468     roc_auc       0.261583   \n",
      "6          CatBoost_r137_BAG_L1   0.739432     roc_auc       0.098287   \n",
      "7             LightGBMXT_BAG_L1   0.739359     roc_auc       0.599375   \n",
      "8           CatBoost_r69_BAG_L1   0.739355     roc_auc       0.046877   \n",
      "9            CatBoost_r9_BAG_L1   0.739273     roc_auc       0.212877   \n",
      "10          CatBoost_r50_BAG_L1   0.739272     roc_auc       0.214721   \n",
      "11              LightGBM_BAG_L1   0.739224     roc_auc       0.446198   \n",
      "12           XGBoost_r89_BAG_L1   0.739219     roc_auc       0.966727   \n",
      "13         LightGBM_r131_BAG_L1   0.739060     roc_auc       1.962052   \n",
      "14               XGBoost_BAG_L1   0.738941     roc_auc       0.979697   \n",
      "15         LightGBM_r130_BAG_L1   0.738841     roc_auc       0.405443   \n",
      "16          XGBoost_r194_BAG_L1   0.738611     roc_auc       0.368062   \n",
      "17         LightGBM_r188_BAG_L1   0.738407     roc_auc       0.796199   \n",
      "18         LightGBMLarge_BAG_L1   0.738164     roc_auc       0.702059   \n",
      "19  NeuralNetFastAI_r102_BAG_L1   0.737962     roc_auc       1.049597   \n",
      "20  NeuralNetFastAI_r143_BAG_L1   0.737799     roc_auc       1.290426   \n",
      "21         LightGBM_r161_BAG_L1   0.737564     roc_auc       2.249569   \n",
      "22       NeuralNetFastAI_BAG_L1   0.737403     roc_auc       1.618402   \n",
      "23           XGBoost_r33_BAG_L1   0.737128     roc_auc       2.092119   \n",
      "24  NeuralNetFastAI_r191_BAG_L1   0.735996     roc_auc       3.293452   \n",
      "25  NeuralNetFastAI_r145_BAG_L1   0.735525     roc_auc       4.624325   \n",
      "26  NeuralNetFastAI_r103_BAG_L1   0.734499     roc_auc       2.671064   \n",
      "27        ExtraTreesEntr_BAG_L1   0.730391     roc_auc      13.385036   \n",
      "28        ExtraTreesGini_BAG_L1   0.730041     roc_auc      13.018558   \n",
      "29         LightGBM_r196_BAG_L1   0.729182     roc_auc       0.313747   \n",
      "30      RandomForestEntr_BAG_L1   0.729058     roc_auc      13.383244   \n",
      "31   NeuralNetFastAI_r11_BAG_L1   0.728954     roc_auc       4.956915   \n",
      "32      RandomForestGini_BAG_L1   0.727898     roc_auc      13.184534   \n",
      "33       ExtraTrees_r172_BAG_L1   0.720789     roc_auc      13.736412   \n",
      "34        ExtraTrees_r42_BAG_L1   0.718941     roc_auc      14.300044   \n",
      "35     RandomForest_r195_BAG_L1   0.697310     roc_auc      12.858651   \n",
      "36        KNeighborsUnif_BAG_L1   0.654484     roc_auc      68.168900   \n",
      "37        KNeighborsDist_BAG_L1   0.638913     roc_auc      68.029419   \n",
      "\n",
      "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   6431.927575                0.046890          31.558441            2   \n",
      "1    137.175091                3.351468         137.175091            1   \n",
      "2    197.928942                0.081565         197.928942            1   \n",
      "3    435.445687                0.066689         435.445687            1   \n",
      "4    140.417531                0.057192         140.417531            1   \n",
      "5    173.602765                0.261583         173.602765            1   \n",
      "6    278.501825                0.098287         278.501825            1   \n",
      "7     37.337628                0.599375          37.337628            1   \n",
      "8    202.613361                0.046877         202.613361            1   \n",
      "9    380.369048                0.212877         380.369048            1   \n",
      "10   142.933426                0.214721         142.933426            1   \n",
      "11    35.430978                0.446198          35.430978            1   \n",
      "12   259.267329                0.966727         259.267329            1   \n",
      "13    74.111807                1.962052          74.111807            1   \n",
      "14   175.391814                0.979697         175.391814            1   \n",
      "15    36.314429                0.405443          36.314429            1   \n",
      "16    43.285868                0.368062          43.285868            1   \n",
      "17    48.803617                0.796199          48.803617            1   \n",
      "18    44.596944                0.702059          44.596944            1   \n",
      "19   435.541548                1.049597         435.541548            1   \n",
      "20   776.257269                1.290426         776.257269            1   \n",
      "21   110.509724                2.249569         110.509724            1   \n",
      "22   866.657242                1.618402         866.657242            1   \n",
      "23   448.019802                2.092119         448.019802            1   \n",
      "24  2309.722020                3.293452        2309.722020            1   \n",
      "25  2976.164875                4.624325        2976.164875            1   \n",
      "26  1338.583270                2.671064        1338.583270            1   \n",
      "27    42.924301               13.385036          42.924301            1   \n",
      "28    41.334926               13.018558          41.334926            1   \n",
      "29    28.700237                0.313747          28.700237            1   \n",
      "30    44.597038               13.383244          44.597038            1   \n",
      "31  2793.964148                4.956915        2793.964148            1   \n",
      "32    42.368613               13.184534          42.368613            1   \n",
      "33   271.112558               13.736412         271.112558            1   \n",
      "34   210.928923               14.300044         210.928923            1   \n",
      "35   199.101240               12.858651         199.101240            1   \n",
      "36     0.366157               68.168900           0.366157            1   \n",
      "37     0.370304               68.029419           0.370304            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0        True         38  \n",
      "1        True         17  \n",
      "2        True          7  \n",
      "3        True         22  \n",
      "4        True         13  \n",
      "5        True         36  \n",
      "6        True         20  \n",
      "7        True          3  \n",
      "8        True         32  \n",
      "9        True         16  \n",
      "10       True         28  \n",
      "11       True          4  \n",
      "12       True         26  \n",
      "13       True         14  \n",
      "14       True         11  \n",
      "15       True         27  \n",
      "16       True         30  \n",
      "17       True         24  \n",
      "18       True         12  \n",
      "19       True         21  \n",
      "20       True         35  \n",
      "21       True         34  \n",
      "22       True         10  \n",
      "23       True         18  \n",
      "24       True         15  \n",
      "25       True         25  \n",
      "26       True         33  \n",
      "27       True          9  \n",
      "28       True          8  \n",
      "29       True         37  \n",
      "30       True          6  \n",
      "31       True         29  \n",
      "32       True          5  \n",
      "33       True         31  \n",
      "34       True         19  \n",
      "35       True         23  \n",
      "36       True          1  \n",
      "37       True          2  \n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분할\n",
    "Total_X_train, Total_X_test, Total_y_train, Total_y_test = train_test_split(Total_X,\n",
    "                                                                            Total_y,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42,\n",
    "                                                                            stratify=Total_y)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터를 합쳐서 DataFrame 생성\n",
    "train_data = pd.concat([Total_X_train, Total_y_train], axis=1)\n",
    "test_data = pd.concat([Total_X_test, Total_y_test], axis=1)\n",
    "\n",
    "# 전체 데이터를 하나로 합침\n",
    "combined_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# 타겟 컬럼 이름\n",
    "label = Total_y_train.name\n",
    "eval_metric = 'roc_auc'\n",
    "time_limit = 60 * 60 * 6  # 6시간\n",
    "\n",
    "# 모델 학습 (CPU만 사용)\n",
    "predictor = TabularPredictor(\n",
    "    label=label, eval_metric=eval_metric\n",
    ").fit(combined_data, \n",
    "    presets='best_quality', \n",
    "    time_limit=time_limit, \n",
    "    num_gpus=0, \n",
    "    ag_args_fit={'num_cpus': 16, 'num_gpus': 0}\n",
    ")\n",
    "\n",
    "# 리더보드 출력\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "print(leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PUBLIC 0.7403204458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_test 데이터의 타겟 변수 예측\n",
    "Total_pred_proba = predictor.predict_proba(Total_test.drop('ID', axis=1))\n",
    "Total_test['probability'] = Total_pred_proba.iloc[:, 1]\n",
    "\n",
    "# 최종 제출 파일 생성\n",
    "submission = Total_test[['ID', 'probability']]\n",
    "submission = submission.sort_values(by='ID')\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission.to_csv('../submission/code47_autogluon4.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
