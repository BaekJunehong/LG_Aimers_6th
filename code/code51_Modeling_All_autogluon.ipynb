{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 난임 환자 대상 임신 성공 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGAimers 6th 온라인 해커톤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "Total_train = pd.read_csv('../data/Total_train_dataset_51.csv')\n",
    "Total_test = pd.read_csv('../data/Total_test_dataset_51.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon.core as ag\n",
    "\n",
    "train_data = TabularDataset(Total_train)\n",
    "test_data = TabularDataset(Total_test)\n",
    "\n",
    "label = '임신_성공_여부'\n",
    "eval_metric = 'roc_auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/ag-20250224_1\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       10.14 GB / 15.86 GB (64.0%)\n",
      "Disk Space Avail:   191.58 GB / 476.30 GB (40.2%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-02-24 00:42:36,112\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Beginning AutoGluon training ... Time limit = 892s\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_1\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Train Data Rows:    227861\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Train Data Columns: 88\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Label Column:       임신_성공_여부\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tAvailable Memory:                    9611.43 MB\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tTrain Data (Original)  Memory Usage: 166.24 MB (1.7% of available memory)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t\tNote: Converting 19 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tUnused Original Features (Count: 3): ['ID', '특정_시술_유형_IVI', '정자_출처_미할당']\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t('int', [])    : 2 | ['특정_시술_유형_IVI', '정자_출처_미할당']\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t('object', []) : 1 | ['ID']\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t('float', []) : 50 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t('int', [])   : 35 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t('float', [])     : 50 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t('int', [])       : 18 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t('int', ['bool']) : 17 | ['시술_유형_IVF', '시술_유형_DI', '특정_시술_유형_AH', '특정_시술_유형_BLASTOCYST', '특정_시술_유형_GenericDI', ...]\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t2.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t85 features in original data used to generate 85 features in processed data.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tTrain Data (Processed) Memory Usage: 121.91 MB (1.2% of available memory)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Data preprocessing and feature engineering runtime = 2.15s ...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 593.03s of the 889.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.6538\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.43s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t51.66s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 537.36s of the 834.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.6416\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.4s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t51.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 485.31s of the 782.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.79%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7381\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t8.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t1.82s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 467.99s of the 764.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.07%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7383\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t6.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t1.2s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 457.47s of the 754.20s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7261\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t38.13s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t12.93s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 405.58s of the 702.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7274\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t38.92s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t12.53s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 353.43s of the 650.16s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.01%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7387\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t75.95s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 274.41s of the 571.14s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7278\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t35.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t12.28s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 225.73s of the 522.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7282\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t37.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t12.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 175.64s of the 472.37s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.55% memory usage per fold, 66.20%/80.00% total).\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=16.55%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.737\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t128.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t3.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 43.36s of the 340.09s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=12.45%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7372\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t35.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.94s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4.79s of the 301.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.82%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=3852, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     model = self._train_single(**model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m                                                                                                                                      ^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m            ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     raise value.as_instanceof_cause()\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=3852, ip=127.0.0.1)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m           ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     dataset = self._process_train_data(\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     self.processor = create_preprocessor(\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m                      ^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m   File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m     return ColumnTransformer(\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 294.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.429, 'LightGBMXT_BAG_L1': 0.19, 'LightGBM_BAG_L1': 0.19, 'NeuralNetFastAI_BAG_L1': 0.143, 'RandomForestEntr_BAG_L1': 0.048}\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7392\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t8.31s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 285.96s of the 285.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.78%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.739\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t7.84s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t1.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 269.00s of the 268.94s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.81%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7388\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t6.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.75s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 258.42s of the 258.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7511\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t42.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t13.67s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 201.76s of the 201.70s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7509\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t45.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t13.72s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 141.34s of the 141.28s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.83%)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.739\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t64.1s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 73.98s of the 73.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.7517\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t35.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t13.19s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 24.52s of the 24.46s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 159 due to low time. Expected time usage reduced from 45.1s -> 24.1s...\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 13.18s compared to 10.77s of available time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L2.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 3.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.421, 'RandomForestGini_BAG_L2': 0.316, 'RandomForestEntr_BAG_L2': 0.263}\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.754\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t12.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m AutoGluon training complete, total runtime = 901.88s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 990.6 rows/s (45573 batch size)\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_1\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=18248)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L2       0.742265   0.739219     roc_auc        4.283658      18.894682  267.437096                 0.015626                0.030663           8.307738            2       True         12\n",
      "1           CatBoost_BAG_L1       0.742195   0.738737     roc_auc        0.504383       0.097757   75.947106                 0.504383                0.097757          75.947106            1       True          7\n",
      "2           LightGBM_BAG_L2       0.742067   0.738825     roc_auc       19.782348     161.052646  412.570121                 0.269193                0.753280           6.713153            2       True         14\n",
      "3         LightGBMXT_BAG_L2       0.741893   0.739030     roc_auc       19.814859     161.328808  413.699251                 0.301704                1.029442           7.842283            2       True         13\n",
      "4           CatBoost_BAG_L2       0.741768   0.738951     roc_auc       19.642207     160.398743  469.954711                 0.129052                0.099377          64.097744            2       True         17\n",
      "5           LightGBM_BAG_L1       0.741506   0.738300     roc_auc        0.300881       1.197218    6.933396                 0.300881                1.197218           6.933396            1       True          4\n",
      "6    NeuralNetFastAI_BAG_L1       0.741345   0.736992     roc_auc        2.201040       3.219371  128.796227                 2.201040                3.219371         128.796227            1       True         10\n",
      "7            XGBoost_BAG_L1       0.740849   0.737199     roc_auc        0.883161       0.943103   35.025627                 0.883161                0.943103          35.025627            1       True         11\n",
      "8         LightGBMXT_BAG_L1       0.740682   0.738061     roc_auc        0.566410       1.819524    8.530011                 0.566410                1.819524           8.530011            1       True          3\n",
      "9       WeightedEnsemble_L3       0.738396   0.753965     roc_auc       21.680329     200.911442  542.353667                 0.011913                0.031252          12.899090            3       True         19\n",
      "10    ExtraTreesGini_BAG_L2       0.738236   0.751670     roc_auc       20.182572     173.493108  441.352584                 0.669417               13.193742          35.495617            2       True         18\n",
      "11  RandomForestEntr_BAG_L2       0.737401   0.750918     roc_auc       20.242764     174.020350  451.786099                 0.729609               13.720984          45.929132            2       True         16\n",
      "12  RandomForestGini_BAG_L2       0.735577   0.751054     roc_auc       20.269390     173.965463  448.029829                 0.756235               13.666097          42.172861            2       True         15\n",
      "13    ExtraTreesEntr_BAG_L1       0.732582   0.728224     roc_auc        0.698312      12.371896   37.038286                 0.698312               12.371896          37.038286            1       True          9\n",
      "14    ExtraTreesGini_BAG_L1       0.732074   0.727751     roc_auc        0.701591      12.277276   35.709386                 0.701591               12.277276          35.709386            1       True          8\n",
      "15  RandomForestEntr_BAG_L1       0.730023   0.727352     roc_auc        0.695318      12.530148   38.922618                 0.695318               12.530148          38.922618            1       True          6\n",
      "16  RandomForestGini_BAG_L1       0.729634   0.726069     roc_auc        0.733162      12.927770   38.127201                 0.733162               12.927770          38.127201            1       True          5\n",
      "17    KNeighborsUnif_BAG_L1       0.655797   0.653845     roc_auc        5.892130      51.656072    0.426586                 5.892130               51.656072           0.426586            1       True          1\n",
      "18    KNeighborsDist_BAG_L1       0.644542   0.641636     roc_auc        6.336768      51.259229    0.400525                 6.336768               51.259229           0.400525            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t935s\t = DyStack   runtime |\t2665s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 2665s\n",
      "AutoGluon will save models to \"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_1\"\n",
      "Train Data Rows:    256344\n",
      "Train Data Columns: 88\n",
      "Label Column:       임신_성공_여부\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8908.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 187.02 MB (2.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 19 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 50 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\t\t('int', [])   : 37 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 50 | ['시술_당시_나이', '임신_시도_또는_마지막_임신_경과_연수', '단일_배아_이식_여부', '착상_전_유전_검사_사용_여부', '착상_전_유전_진단_사용_여부', ...]\n",
      "\t\t('int', [])       : 18 | ['배란_자극_여부', '남성_주_불임_원인', '남성_부_불임_원인', '여성_주_불임_원인', '여성_부_불임_원인', ...]\n",
      "\t\t('int', ['bool']) : 19 | ['시술_유형_IVF', '시술_유형_DI', '특정_시술_유형_AH', '특정_시술_유형_BLASTOCYST', '특정_시술_유형_GenericDI', ...]\n",
      "\t1.8s = Fit runtime\n",
      "\t87 features in original data used to generate 87 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 137.64 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2662.88s of the 2662.86s of remaining time.\n",
      "\t0.6546\t = Validation score   (roc_auc)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t78.66s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2580.04s of the 2580.03s of remaining time.\n",
      "\t0.6421\t = Validation score   (roc_auc)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t78.81s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2500.25s of the 2500.23s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.65%)\n",
      "\t0.7383\t = Validation score   (roc_auc)\n",
      "\t10.31s\t = Training   runtime\n",
      "\t2.16s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2486.04s of the 2486.02s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.57%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t8.44s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2475.09s of the 2475.08s of remaining time.\n",
      "\t0.7276\t = Validation score   (roc_auc)\n",
      "\t42.39s\t = Training   runtime\n",
      "\t13.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2418.87s of the 2418.86s of remaining time.\n",
      "\t0.7285\t = Validation score   (roc_auc)\n",
      "\t44.52s\t = Training   runtime\n",
      "\t13.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2360.16s of the 2360.15s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.84%)\n",
      "\t0.7391\t = Validation score   (roc_auc)\n",
      "\t63.67s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2294.44s of the 2294.43s of remaining time.\n",
      "\t0.7288\t = Validation score   (roc_auc)\n",
      "\t41.41s\t = Training   runtime\n",
      "\t12.94s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2239.33s of the 2239.32s of remaining time.\n",
      "\t0.7295\t = Validation score   (roc_auc)\n",
      "\t43.07s\t = Training   runtime\n",
      "\t13.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2182.36s of the 2182.35s of remaining time.\n",
      "\tMemory not enough to fit 5 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.98% memory usage per fold, 67.92%/80.00% total).\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=4, gpus=0, memory=16.98%)\n",
      "\t0.7375\t = Validation score   (roc_auc)\n",
      "\t262.66s\t = Training   runtime\n",
      "\t2.33s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1917.34s of the 1917.32s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=12.82%)\n",
      "\t0.7387\t = Validation score   (roc_auc)\n",
      "\t157.27s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1756.32s of the 1756.31s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.97%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=17444, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=17444, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1750.83s of the 1750.81s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.08%)\n",
      "2025-02-24 01:13:26,229\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:13:26,235\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:13:26,239\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:13:26,241\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7379\t = Validation score   (roc_auc)\n",
      "\t10.83s\t = Training   runtime\n",
      "\t2.14s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1737.23s of the 1737.21s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.80%)\n",
      "\t0.739\t = Validation score   (roc_auc)\n",
      "\t47.64s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1687.18s of the 1687.17s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.61%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20076, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20076, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1681.77s of the 1681.75s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.81%)\n",
      "2025-02-24 01:14:34,825\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:14:34,825\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:14:34,825\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:14:34,825\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t25.21s\t = Training   runtime\n",
      "\t6.37s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1653.00s of the 1652.99s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=15.94%)\n",
      "\t0.7373\t = Validation score   (roc_auc)\n",
      "\t911.52s\t = Training   runtime\n",
      "\t5.81s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 738.29s of the 738.27s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.87%)\n",
      "\t0.7389\t = Validation score   (roc_auc)\n",
      "\t96.04s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 639.86s of the 639.85s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=9.41%)\n",
      "\t0.7384\t = Validation score   (roc_auc)\n",
      "\t61.29s\t = Training   runtime\n",
      "\t13.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 573.99s of the 573.97s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=8.58%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=20140, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 2106, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1993, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 298, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\bagged_ensemble_model.py\", line 724, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ray\\_private\\worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=20140, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1862, in ray._raylet.execute_task\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\ensemble\\fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 925, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 201, in _fit\n",
      "    train_dataset = self._generate_dataset(X, y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 669, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 734, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\utils\\data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 568.61s of the 568.59s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=15.65%)\n",
      "2025-02-24 01:33:07,987\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:33:07,987\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-02-24 01:33:07,987\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7367\t = Validation score   (roc_auc)\n",
      "\t413.92s\t = Training   runtime\n",
      "\t5.03s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 151.63s of the 151.61s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 181 due to low time. Expected time usage reduced from 249.7s -> 151.2s...\n",
      "2025-02-24 01:40:07,775\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7184\t = Validation score   (roc_auc)\n",
      "\t125.19s\t = Training   runtime\n",
      "\t8.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 17.35s of the 17.34s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=10.16%)\n",
      "\t0.7368\t = Validation score   (roc_auc)\n",
      "\t14.8s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 0.12s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.16, 'XGBoost_BAG_L1': 0.16, 'NeuralNetFastAI_r191_BAG_L1': 0.16, 'LightGBM_BAG_L1': 0.12, 'NeuralNetFastAI_BAG_L1': 0.12, 'CatBoost_r9_BAG_L1': 0.08, 'LightGBM_r96_BAG_L1': 0.08, 'ExtraTreesEntr_BAG_L1': 0.04, 'CatBoost_r177_BAG_L1': 0.04, 'XGBoost_r33_BAG_L1': 0.04}\n",
      "\t0.7398\t = Validation score   (roc_auc)\n",
      "\t17.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2682.02s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1600.7 rows/s (51269 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\juneh\\OneDrive\\바탕 화면\\git_Aimers6th\\LG_Aimers_6th\\code\\AutogluonModels\\ag-20250224_1\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# 시간 제한 설정 (예: 60분)\n",
    "time_limit =  1 * 60 * 60\n",
    "\n",
    "# # GPU를 사용할 수 없는 모델을 제외하도록 설정\n",
    "# exclude_model_types = [\n",
    "#     'KNN',  # K-Nearest Neighbors\n",
    "#     'RF',   # Random Forest\n",
    "#     'XT',   # Extra Trees\n",
    "#     'LR',   # Linear Regression\n",
    "#     'NN'    # Tabular Neural Network\n",
    "# ]\n",
    "\n",
    "# TabularPredictor 객체 생성 및 학습\n",
    "predictor = TabularPredictor(\n",
    "    label=label,\n",
    "    eval_metric=eval_metric,\n",
    "    path='AutogluonModels/ag-20250224_1'  # 모델 저장 경로\n",
    ").fit(\n",
    "    train_data,\n",
    "    presets='best_quality',  # 'best_quality', 'medium_quality', 'good_quality' 등의 프리셋 설정\n",
    "    # num_stack_levels=0,  # 스택 레벨 설정 / dynamic_stacking=True(디폴트)인 경우 무시\n",
    "    num_bag_folds=5,  # 배깅 설정\n",
    "    time_limit=time_limit,  # 시간 제한 설정\n",
    "    # num_gpus=1,  # GPU 사용 설정\n",
    "    # excluded_model_types=exclude_model_types  # 제외할 모델 유형 설정\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          model  score_val eval_metric  pred_time_val  \\\n",
      "0           WeightedEnsemble_L2   0.739817     roc_auc      42.570715   \n",
      "1               CatBoost_BAG_L1   0.739133     roc_auc       0.112236   \n",
      "2          CatBoost_r177_BAG_L1   0.739006     roc_auc       0.106326   \n",
      "3            CatBoost_r9_BAG_L1   0.738942     roc_auc       0.427500   \n",
      "4               LightGBM_BAG_L1   0.738897     roc_auc       1.277348   \n",
      "5          LightGBM_r131_BAG_L1   0.738891     roc_auc       6.371697   \n",
      "6                XGBoost_BAG_L1   0.738713     roc_auc       1.104254   \n",
      "7           LightGBM_r96_BAG_L1   0.738364     roc_auc      13.201086   \n",
      "8             LightGBMXT_BAG_L1   0.738269     roc_auc       2.155192   \n",
      "9          LightGBMLarge_BAG_L1   0.737884     roc_auc       2.137181   \n",
      "10       NeuralNetFastAI_BAG_L1   0.737462     roc_auc       2.330115   \n",
      "11  NeuralNetFastAI_r191_BAG_L1   0.737278     roc_auc       5.805177   \n",
      "12         CatBoost_r137_BAG_L1   0.736813     roc_auc       0.112270   \n",
      "13           XGBoost_r33_BAG_L1   0.736733     roc_auc       5.028984   \n",
      "14        ExtraTreesEntr_BAG_L1   0.729540     roc_auc      13.149029   \n",
      "15        ExtraTreesGini_BAG_L1   0.728772     roc_auc      12.943942   \n",
      "16      RandomForestEntr_BAG_L1   0.728491     roc_auc      13.344697   \n",
      "17      RandomForestGini_BAG_L1   0.727622     roc_auc      13.070110   \n",
      "18        ExtraTrees_r42_BAG_L1   0.718371     roc_auc       8.464380   \n",
      "19        KNeighborsUnif_BAG_L1   0.654629     roc_auc      78.660572   \n",
      "20        KNeighborsDist_BAG_L1   0.642139     roc_auc      78.808385   \n",
      "\n",
      "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   2082.646703                0.028659          17.128781            2   \n",
      "1     63.666353                0.112236          63.666353            1   \n",
      "2     47.636391                0.106326          47.636391            1   \n",
      "3     96.044116                0.427500          96.044116            1   \n",
      "4      8.435173                1.277348           8.435173            1   \n",
      "5     25.212863                6.371697          25.212863            1   \n",
      "6    157.269733                1.104254         157.269733            1   \n",
      "7     61.290442               13.201086          61.290442            1   \n",
      "8     10.313149                2.155192          10.313149            1   \n",
      "9     10.832702                2.137181          10.832702            1   \n",
      "10   262.662930                2.330115         262.662930            1   \n",
      "11   911.519055                5.805177         911.519055            1   \n",
      "12    14.801619                0.112270          14.801619            1   \n",
      "13   413.920393                5.028984         413.920393            1   \n",
      "14    43.073336               13.149029          43.073336            1   \n",
      "15    41.407252               12.943942          41.407252            1   \n",
      "16    44.516738               13.344697          44.516738            1   \n",
      "17    42.387278               13.070110          42.387278            1   \n",
      "18   125.190368                8.464380         125.190368            1   \n",
      "19     0.559979               78.660572           0.559979            1   \n",
      "20     0.551085               78.808385           0.551085            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0        True         21  \n",
      "1        True          7  \n",
      "2        True         13  \n",
      "3        True         16  \n",
      "4        True          4  \n",
      "5        True         14  \n",
      "6        True         11  \n",
      "7        True         17  \n",
      "8        True          3  \n",
      "9        True         12  \n",
      "10       True         10  \n",
      "11       True         15  \n",
      "12       True         20  \n",
      "13       True         18  \n",
      "14       True          9  \n",
      "15       True          8  \n",
      "16       True          6  \n",
      "17       True          5  \n",
      "18       True         19  \n",
      "19       True          1  \n",
      "20       True          2  \n"
     ]
    }
   ],
   "source": [
    "print(predictor.leaderboard(silent = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.feature_importance(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 모델 가져오기\n",
    "model_to_use = predictor.model_best\n",
    "\n",
    "# 확률 예측\n",
    "prob_predictions = predictor.predict_proba(test_data, model=model_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  probability\n",
      "0  TEST_00000     0.001691\n",
      "1  TEST_00001     0.004895\n",
      "2  TEST_00002     0.161748\n",
      "3  TEST_00003     0.103157\n",
      "4  TEST_00004     0.515951\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 test_data에 추가\n",
    "test_data['probability'] = prob_predictions.iloc[:, 1]\n",
    "\n",
    "# 최종 제출 파일 생성\n",
    "submission = test_data[['ID', 'probability']]\n",
    "submission = submission.sort_values(by='ID')\n",
    "\n",
    "# 제출 파일 저장\n",
    "submission.to_csv('../submission/code51_all_lgbm.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# 예측 결과 확인\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이콘 PUBLIC 0.7404194168"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
