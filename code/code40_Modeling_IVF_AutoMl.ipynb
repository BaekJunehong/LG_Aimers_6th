{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 난임 환자 대상 임신 성공 여부 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGAimers 6th 온라인 해커톤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "IVF_train = pd.read_csv('../data/IVF_train_dataset_40.csv')\n",
    "IVF_test = pd.read_csv('../data/IVF_test_dataset_40.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 열을 제외한 특성과 타겟 변수 분리\n",
    "IVF_X = IVF_train.drop(['임신_성공_여부', 'ID'], axis=1)\n",
    "IVF_y = IVF_train['임신_성공_여부']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVF_X shape: (250052, 66)\n",
      "IVF_test shape: (87891, 62)\n"
     ]
    }
   ],
   "source": [
    "print(f\"IVF_X shape: {IVF_X.shape}\")\n",
    "print(f\"IVF_test shape: {IVF_test.drop('ID', axis=1).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IVF_categorical_columns = [\n",
    "    \"시술_당시_나이\",\n",
    "    \"난자_출처\",\n",
    "    \"정자_출처\",\n",
    "    \"난자_기증자_나이\",\n",
    "    \"정자_기증자_나이\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 범주형 변수를 문자열로 변환\n",
    "IVF_X[IVF_categorical_columns] = IVF_X[IVF_categorical_columns].astype(str)\n",
    "IVF_test[IVF_categorical_columns] = IVF_test[IVF_categorical_columns].astype(str)\n",
    "\n",
    "# OrdinalEncoder를 사용하여 범주형 변수 인코딩\n",
    "IVF_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "IVF_X[IVF_categorical_columns] = IVF_encoder.fit_transform(IVF_X[IVF_categorical_columns])\n",
    "IVF_test[IVF_categorical_columns] = IVF_encoder.transform(IVF_test[IVF_categorical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "IVF_X_train, IVF_X_test, IVF_y_train, IVF_y_test = train_test_split(IVF_X, IVF_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-18 19:02:37] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 02-18 19:02:37] {1691} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 02-18 19:02:37] {1789} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 02-18 19:02:37] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 02-18 19:02:37] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:37] {2346} INFO - Estimated sufficient time budget=11165s. Estimated necessary time budget=274s.\n",
      "[flaml.automl.logger: 02-18 19:02:37] {2398} INFO -  at 2.0s,\testimator lgbm's best error=0.2914,\tbest estimator lgbm's best error=0.2914\n",
      "[flaml.automl.logger: 02-18 19:02:37] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:37] {2398} INFO -  at 2.1s,\testimator lgbm's best error=0.2914,\tbest estimator lgbm's best error=0.2914\n",
      "[flaml.automl.logger: 02-18 19:02:37] {2219} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.2s,\testimator lgbm's best error=0.2834,\tbest estimator lgbm's best error=0.2834\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.2s,\testimator xgboost's best error=0.2914,\tbest estimator lgbm's best error=0.2834\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.3s,\testimator lgbm's best error=0.2741,\tbest estimator lgbm's best error=0.2741\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.4s,\testimator lgbm's best error=0.2741,\tbest estimator lgbm's best error=0.2741\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.5s,\testimator lgbm's best error=0.2741,\tbest estimator lgbm's best error=0.2741\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.6s,\testimator lgbm's best error=0.2726,\tbest estimator lgbm's best error=0.2726\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.6s,\testimator lgbm's best error=0.2726,\tbest estimator lgbm's best error=0.2726\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 2.7s,\testimator xgboost's best error=0.2913,\tbest estimator lgbm's best error=0.2726\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2398} INFO -  at 3.1s,\testimator extra_tree's best error=0.3146,\tbest estimator lgbm's best error=0.2726\n",
      "[flaml.automl.logger: 02-18 19:02:38] {2219} INFO - iteration 11, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2398} INFO -  at 3.4s,\testimator rf's best error=0.3191,\tbest estimator lgbm's best error=0.2726\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2219} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2398} INFO -  at 3.6s,\testimator lgbm's best error=0.2709,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2219} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2398} INFO -  at 4.0s,\testimator rf's best error=0.2942,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2219} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2398} INFO -  at 4.1s,\testimator lgbm's best error=0.2709,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:39] {2219} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:40] {2398} INFO -  at 4.5s,\testimator extra_tree's best error=0.2858,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:40] {2219} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:40] {2398} INFO -  at 5.0s,\testimator lgbm's best error=0.2709,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:40] {2219} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:41] {2398} INFO -  at 5.4s,\testimator extra_tree's best error=0.2858,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:41] {2219} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:41] {2398} INFO -  at 5.6s,\testimator lgbm's best error=0.2709,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:41] {2219} INFO - iteration 19, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:02:41] {2398} INFO -  at 6.0s,\testimator rf's best error=0.2942,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:41] {2219} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:02:42] {2398} INFO -  at 6.5s,\testimator rf's best error=0.2820,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:42] {2219} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:02:42] {2398} INFO -  at 6.8s,\testimator rf's best error=0.2820,\tbest estimator lgbm's best error=0.2709\n",
      "[flaml.automl.logger: 02-18 19:02:42] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:42] {2398} INFO -  at 7.1s,\testimator lgbm's best error=0.2682,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:42] {2219} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:43] {2398} INFO -  at 7.5s,\testimator lgbm's best error=0.2682,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:43] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:43] {2398} INFO -  at 8.0s,\testimator extra_tree's best error=0.2858,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:43] {2219} INFO - iteration 25, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:02:45] {2398} INFO -  at 9.2s,\testimator catboost's best error=0.2703,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:45] {2219} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:45] {2398} INFO -  at 9.5s,\testimator extra_tree's best error=0.2858,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:45] {2219} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:45] {2398} INFO -  at 9.7s,\testimator lgbm's best error=0.2682,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:45] {2219} INFO - iteration 28, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:02:55] {2398} INFO -  at 19.9s,\testimator catboost's best error=0.2686,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:55] {2219} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:56] {2398} INFO -  at 20.4s,\testimator extra_tree's best error=0.2858,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:56] {2219} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:56] {2398} INFO -  at 20.7s,\testimator extra_tree's best error=0.2858,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:56] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:56] {2398} INFO -  at 21.0s,\testimator lgbm's best error=0.2682,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:56] {2219} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:57] {2398} INFO -  at 21.3s,\testimator lgbm's best error=0.2682,\tbest estimator lgbm's best error=0.2682\n",
      "[flaml.automl.logger: 02-18 19:02:57] {2219} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:57] {2398} INFO -  at 21.9s,\testimator lgbm's best error=0.2665,\tbest estimator lgbm's best error=0.2665\n",
      "[flaml.automl.logger: 02-18 19:02:57] {2219} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:02:58] {2398} INFO -  at 22.4s,\testimator extra_tree's best error=0.2808,\tbest estimator lgbm's best error=0.2665\n",
      "[flaml.automl.logger: 02-18 19:02:58] {2219} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:58] {2398} INFO -  at 22.9s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:02:58] {2219} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:02:59] {2398} INFO -  at 23.5s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:02:59] {2219} INFO - iteration 37, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:02:59] {2398} INFO -  at 24.1s,\testimator catboost's best error=0.2686,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:02:59] {2219} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:00] {2398} INFO -  at 24.5s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:00] {2219} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:01] {2398} INFO -  at 25.3s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:01] {2219} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:01] {2398} INFO -  at 26.0s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:01] {2219} INFO - iteration 41, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:03:02] {2398} INFO -  at 26.5s,\testimator rf's best error=0.2820,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:02] {2219} INFO - iteration 42, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:03:02] {2398} INFO -  at 26.9s,\testimator rf's best error=0.2820,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:02] {2219} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:03] {2398} INFO -  at 27.3s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:03] {2219} INFO - iteration 44, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:03:03] {2398} INFO -  at 27.8s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:03] {2219} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:03:04] {2398} INFO -  at 28.2s,\testimator extra_tree's best error=0.2808,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:04] {2219} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:03:04] {2398} INFO -  at 28.7s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:04] {2219} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:05] {2398} INFO -  at 29.3s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:05] {2219} INFO - iteration 48, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:03:05] {2398} INFO -  at 29.7s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:05] {2219} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2398} INFO -  at 30.2s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2219} INFO - iteration 50, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2398} INFO -  at 30.8s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2219} INFO - iteration 51, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2398} INFO -  at 30.9s,\testimator xgb_limitdepth's best error=0.2766,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2219} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2398} INFO -  at 31.0s,\testimator xgb_limitdepth's best error=0.2764,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:06] {2219} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:07] {2398} INFO -  at 31.7s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:07] {2219} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:08] {2398} INFO -  at 32.5s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:08] {2219} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:08] {2398} INFO -  at 32.9s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:08] {2219} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:09] {2398} INFO -  at 33.4s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:09] {2219} INFO - iteration 57, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:03:09] {2398} INFO -  at 33.9s,\testimator extra_tree's best error=0.2808,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:09] {2219} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:10] {2398} INFO -  at 34.6s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:10] {2219} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:10] {2398} INFO -  at 35.0s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:10] {2219} INFO - iteration 60, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:03:11] {2398} INFO -  at 35.5s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:11] {2219} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:12] {2398} INFO -  at 36.3s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:12] {2219} INFO - iteration 62, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:03:27] {2398} INFO -  at 52.0s,\testimator catboost's best error=0.2686,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:27] {2219} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2398} INFO -  at 52.4s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2219} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2398} INFO -  at 52.5s,\testimator xgboost's best error=0.2902,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2219} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2398} INFO -  at 52.6s,\testimator xgboost's best error=0.2834,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2219} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2398} INFO -  at 52.6s,\testimator xgboost's best error=0.2830,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2219} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2398} INFO -  at 52.7s,\testimator xgboost's best error=0.2830,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2219} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2398} INFO -  at 52.8s,\testimator xgboost's best error=0.2743,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2219} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2398} INFO -  at 53.0s,\testimator xgboost's best error=0.2721,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:28] {2219} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:29] {2398} INFO -  at 53.7s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:29] {2219} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:29] {2398} INFO -  at 53.8s,\testimator xgboost's best error=0.2721,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:29] {2219} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:29] {2398} INFO -  at 54.0s,\testimator xgboost's best error=0.2721,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:29] {2219} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2398} INFO -  at 54.2s,\testimator xgboost's best error=0.2713,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2219} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2398} INFO -  at 54.4s,\testimator xgb_limitdepth's best error=0.2747,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2219} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2398} INFO -  at 54.5s,\testimator xgb_limitdepth's best error=0.2747,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2219} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2398} INFO -  at 54.7s,\testimator xgb_limitdepth's best error=0.2747,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:30] {2219} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:31] {2398} INFO -  at 56.0s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:31] {2219} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:32] {2398} INFO -  at 56.4s,\testimator lgbm's best error=0.2646,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:32] {2219} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:32] {2398} INFO -  at 56.5s,\testimator xgb_limitdepth's best error=0.2747,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:32] {2219} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:32] {2398} INFO -  at 56.6s,\testimator xgboost's best error=0.2713,\tbest estimator lgbm's best error=0.2646\n",
      "[flaml.automl.logger: 02-18 19:03:32] {2219} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:33] {2398} INFO -  at 57.4s,\testimator lgbm's best error=0.2644,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:33] {2219} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:33] {2398} INFO -  at 57.7s,\testimator xgb_limitdepth's best error=0.2747,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:33] {2219} INFO - iteration 83, current learner lrl1\n",
      "[flaml.automl.logger: 02-18 19:03:34] {2398} INFO -  at 58.5s,\testimator lrl1's best error=0.2818,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:34] {2219} INFO - iteration 84, current learner lrl1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-18 19:03:35] {2398} INFO -  at 59.3s,\testimator lrl1's best error=0.2816,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:35] {2219} INFO - iteration 85, current learner xgb_limitdepth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-18 19:03:35] {2398} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.2697,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:35] {2219} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:35] {2398} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=0.2697,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:35] {2219} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:36] {2398} INFO -  at 60.2s,\testimator xgb_limitdepth's best error=0.2697,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:36] {2219} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:36] {2398} INFO -  at 60.6s,\testimator xgb_limitdepth's best error=0.2697,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:36] {2219} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:36] {2398} INFO -  at 60.9s,\testimator xgb_limitdepth's best error=0.2697,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:36] {2219} INFO - iteration 90, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:37] {2398} INFO -  at 61.2s,\testimator xgboost's best error=0.2709,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:37] {2219} INFO - iteration 91, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:37] {2398} INFO -  at 61.3s,\testimator xgboost's best error=0.2709,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:37] {2219} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:38] {2398} INFO -  at 62.4s,\testimator xgb_limitdepth's best error=0.2670,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:38] {2219} INFO - iteration 93, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:03:38] {2398} INFO -  at 63.0s,\testimator extra_tree's best error=0.2802,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:38] {2219} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:39] {2398} INFO -  at 63.6s,\testimator xgb_limitdepth's best error=0.2670,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:39] {2219} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:41] {2398} INFO -  at 65.7s,\testimator xgb_limitdepth's best error=0.2661,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:41] {2219} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:03:42] {2398} INFO -  at 66.3s,\testimator extra_tree's best error=0.2802,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:42] {2219} INFO - iteration 97, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:42] {2398} INFO -  at 66.8s,\testimator lgbm's best error=0.2644,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:42] {2219} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:43] {2398} INFO -  at 67.8s,\testimator xgb_limitdepth's best error=0.2661,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:43] {2219} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:44] {2398} INFO -  at 68.8s,\testimator xgboost's best error=0.2692,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:44] {2219} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:45] {2398} INFO -  at 69.3s,\testimator xgboost's best error=0.2692,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:45] {2219} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:46] {2398} INFO -  at 71.1s,\testimator xgboost's best error=0.2692,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:46] {2219} INFO - iteration 102, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:48] {2398} INFO -  at 72.7s,\testimator lgbm's best error=0.2644,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:48] {2219} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:03:52] {2398} INFO -  at 77.0s,\testimator xgb_limitdepth's best error=0.2654,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:52] {2219} INFO - iteration 104, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:53] {2398} INFO -  at 77.7s,\testimator xgboost's best error=0.2692,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:53] {2219} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:54] {2398} INFO -  at 78.4s,\testimator lgbm's best error=0.2644,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:54] {2219} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:56] {2398} INFO -  at 80.4s,\testimator xgboost's best error=0.2692,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:56] {2219} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:03:56] {2398} INFO -  at 80.8s,\testimator lgbm's best error=0.2644,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:56] {2219} INFO - iteration 108, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:03:57] {2398} INFO -  at 82.0s,\testimator xgboost's best error=0.2684,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:03:57] {2219} INFO - iteration 109, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:04:00] {2398} INFO -  at 84.7s,\testimator xgb_limitdepth's best error=0.2654,\tbest estimator lgbm's best error=0.2644\n",
      "[flaml.automl.logger: 02-18 19:04:00] {2219} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:04:03] {2398} INFO -  at 87.7s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:03] {2219} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:04:10] {2398} INFO -  at 95.0s,\testimator xgb_limitdepth's best error=0.2654,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:10] {2219} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:04:15] {2398} INFO -  at 99.8s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:15] {2219} INFO - iteration 113, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:04:17] {2398} INFO -  at 101.2s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:17] {2219} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:04:19] {2398} INFO -  at 103.3s,\testimator xgb_limitdepth's best error=0.2653,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:19] {2219} INFO - iteration 115, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:04:19] {2398} INFO -  at 103.8s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:19] {2219} INFO - iteration 116, current learner lrl1\n",
      "[flaml.automl.logger: 02-18 19:04:20] {2398} INFO -  at 104.5s,\testimator lrl1's best error=0.2816,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:20] {2219} INFO - iteration 117, current learner lgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-18 19:04:21] {2398} INFO -  at 105.2s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:21] {2219} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:04:29] {2398} INFO -  at 113.9s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:29] {2219} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:04:30] {2398} INFO -  at 114.5s,\testimator extra_tree's best error=0.2784,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:30] {2219} INFO - iteration 120, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:04:30] {2398} INFO -  at 115.0s,\testimator extra_tree's best error=0.2784,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:30] {2219} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:04:31] {2398} INFO -  at 116.0s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:31] {2219} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:04:32] {2398} INFO -  at 116.6s,\testimator extra_tree's best error=0.2779,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:32] {2219} INFO - iteration 123, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:04:33] {2398} INFO -  at 117.2s,\testimator xgboost's best error=0.2684,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:33] {2219} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:04:33] {2398} INFO -  at 117.8s,\testimator extra_tree's best error=0.2740,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:33] {2219} INFO - iteration 125, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:04:34] {2398} INFO -  at 118.4s,\testimator extra_tree's best error=0.2740,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:34] {2219} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:04:46] {2398} INFO -  at 130.6s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:46] {2219} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:04:47] {2398} INFO -  at 131.3s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:04:47] {2219} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:05:02] {2398} INFO -  at 146.6s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:02] {2219} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:05:16] {2398} INFO -  at 160.3s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:16] {2219} INFO - iteration 130, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:05:19] {2398} INFO -  at 163.6s,\testimator xgboost's best error=0.2684,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:19] {2219} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:05:19] {2398} INFO -  at 164.1s,\testimator extra_tree's best error=0.2740,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:19] {2219} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:05:20] {2398} INFO -  at 164.9s,\testimator extra_tree's best error=0.2731,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:20] {2219} INFO - iteration 133, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:05:21] {2398} INFO -  at 165.9s,\testimator xgboost's best error=0.2684,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:21] {2219} INFO - iteration 134, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:05:22] {2398} INFO -  at 166.8s,\testimator extra_tree's best error=0.2717,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:22] {2219} INFO - iteration 135, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:05:23] {2398} INFO -  at 167.3s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:23] {2219} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:05:25] {2398} INFO -  at 169.4s,\testimator xgboost's best error=0.2664,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:25] {2219} INFO - iteration 137, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:05:26] {2398} INFO -  at 170.3s,\testimator extra_tree's best error=0.2717,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:26] {2219} INFO - iteration 138, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:05:31] {2398} INFO -  at 175.2s,\testimator xgb_limitdepth's best error=0.2653,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:31] {2219} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:05:32] {2398} INFO -  at 176.4s,\testimator xgboost's best error=0.2664,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:32] {2219} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:05:32] {2398} INFO -  at 177.0s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:32] {2219} INFO - iteration 141, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:05:33] {2398} INFO -  at 178.1s,\testimator extra_tree's best error=0.2711,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:33] {2219} INFO - iteration 142, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:05:34] {2398} INFO -  at 178.6s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:34] {2219} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:05:35] {2398} INFO -  at 179.4s,\testimator extra_tree's best error=0.2711,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:35] {2219} INFO - iteration 144, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:05:41] {2398} INFO -  at 185.4s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:41] {2219} INFO - iteration 145, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:05:42] {2398} INFO -  at 187.1s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:05:42] {2219} INFO - iteration 146, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:06:06] {2398} INFO -  at 210.9s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:06] {2219} INFO - iteration 147, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:06:10] {2398} INFO -  at 214.9s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:10] {2219} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:06:20] {2398} INFO -  at 224.9s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:20] {2219} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:06:21] {2398} INFO -  at 225.7s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:21] {2219} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:06:27] {2398} INFO -  at 231.5s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:27] {2219} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:06:28] {2398} INFO -  at 232.8s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:28] {2219} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:06:30] {2398} INFO -  at 234.7s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:30] {2219} INFO - iteration 153, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:06:31] {2398} INFO -  at 235.3s,\testimator rf's best error=0.2793,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:31] {2219} INFO - iteration 154, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:06:39] {2398} INFO -  at 244.1s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:39] {2219} INFO - iteration 155, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:06:41] {2398} INFO -  at 245.6s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:41] {2219} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:06:44] {2398} INFO -  at 248.3s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:44] {2219} INFO - iteration 157, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:06:45] {2398} INFO -  at 249.6s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:45] {2219} INFO - iteration 158, current learner lrl1\n",
      "[flaml.automl.logger: 02-18 19:06:48] {2398} INFO -  at 252.6s,\testimator lrl1's best error=0.2811,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:06:48] {2219} INFO - iteration 159, current learner xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-18 19:07:18] {2398} INFO -  at 283.1s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:18] {2219} INFO - iteration 160, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:07:19] {2398} INFO -  at 283.6s,\testimator rf's best error=0.2790,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:19] {2219} INFO - iteration 161, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:07:20] {2398} INFO -  at 284.3s,\testimator catboost's best error=0.2686,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:20] {2219} INFO - iteration 162, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:07:21] {2398} INFO -  at 285.8s,\testimator extra_tree's best error=0.2711,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:21] {2219} INFO - iteration 163, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:07:26] {2398} INFO -  at 290.2s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:26] {2219} INFO - iteration 164, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:07:31] {2398} INFO -  at 295.2s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:31] {2219} INFO - iteration 165, current learner lrl1\n",
      "[flaml.automl.logger: 02-18 19:07:34] {2398} INFO -  at 298.2s,\testimator lrl1's best error=0.2807,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:34] {2219} INFO - iteration 166, current learner extra_tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-18 19:07:34] {2398} INFO -  at 299.0s,\testimator extra_tree's best error=0.2711,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:34] {2219} INFO - iteration 167, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:07:45] {2398} INFO -  at 309.2s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:45] {2219} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:07:53] {2398} INFO -  at 317.3s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:07:53] {2219} INFO - iteration 169, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:08:04] {2398} INFO -  at 328.5s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:04] {2219} INFO - iteration 170, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:08:05] {2398} INFO -  at 329.5s,\testimator extra_tree's best error=0.2711,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:05] {2219} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:08:06] {2398} INFO -  at 330.2s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:06] {2219} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:08:08] {2398} INFO -  at 333.1s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:08] {2219} INFO - iteration 173, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:08:10] {2398} INFO -  at 334.9s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:10] {2219} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:08:13] {2398} INFO -  at 338.1s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:13] {2219} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:08:49] {2398} INFO -  at 373.5s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:49] {2219} INFO - iteration 176, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:08:50] {2398} INFO -  at 374.6s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:08:50] {2219} INFO - iteration 177, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:09:06] {2398} INFO -  at 390.3s,\testimator catboost's best error=0.2686,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:06] {2219} INFO - iteration 178, current learner lrl1\n",
      "[flaml.automl.logger: 02-18 19:09:09] {2398} INFO -  at 393.3s,\testimator lrl1's best error=0.2807,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:09] {2219} INFO - iteration 179, current learner xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juneh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-18 19:09:13] {2398} INFO -  at 397.4s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:13] {2219} INFO - iteration 180, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:09:28] {2398} INFO -  at 412.5s,\testimator catboost's best error=0.2686,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:28] {2219} INFO - iteration 181, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:09:38] {2398} INFO -  at 422.6s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:38] {2219} INFO - iteration 182, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:09:39] {2398} INFO -  at 423.8s,\testimator extra_tree's best error=0.2711,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:39] {2219} INFO - iteration 183, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:09:48] {2398} INFO -  at 432.4s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:48] {2219} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:09:52] {2398} INFO -  at 436.5s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:52] {2219} INFO - iteration 185, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:09:54] {2398} INFO -  at 438.2s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:54] {2219} INFO - iteration 186, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:09:54] {2398} INFO -  at 438.7s,\testimator rf's best error=0.2790,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:54] {2219} INFO - iteration 187, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:09:58] {2398} INFO -  at 442.9s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:09:58] {2219} INFO - iteration 188, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:10:00] {2398} INFO -  at 444.9s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:10:00] {2219} INFO - iteration 189, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:10:11] {2398} INFO -  at 455.2s,\testimator extra_tree's best error=0.2684,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:10:11] {2219} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:10:14] {2398} INFO -  at 458.7s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:10:14] {2219} INFO - iteration 191, current learner catboost\n",
      "[flaml.automl.logger: 02-18 19:10:30] {2398} INFO -  at 474.4s,\testimator catboost's best error=0.2686,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:10:30] {2219} INFO - iteration 192, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:10:44] {2398} INFO -  at 488.3s,\testimator extra_tree's best error=0.2684,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:10:44] {2219} INFO - iteration 193, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:10:56] {2398} INFO -  at 500.8s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:10:56] {2219} INFO - iteration 194, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:11:03] {2398} INFO -  at 508.0s,\testimator extra_tree's best error=0.2684,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:03] {2219} INFO - iteration 195, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:11:06] {2398} INFO -  at 511.0s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:06] {2219} INFO - iteration 196, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:11:07] {2398} INFO -  at 511.7s,\testimator xgb_limitdepth's best error=0.2653,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:07] {2219} INFO - iteration 197, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:11:08] {2398} INFO -  at 512.2s,\testimator rf's best error=0.2790,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:08] {2219} INFO - iteration 198, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:11:08] {2398} INFO -  at 512.7s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:08] {2219} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:11:19] {2398} INFO -  at 523.6s,\testimator extra_tree's best error=0.2680,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:19] {2219} INFO - iteration 200, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:11:31] {2398} INFO -  at 535.8s,\testimator xgboost's best error=0.2645,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:31] {2219} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:11:38] {2398} INFO -  at 542.8s,\testimator xgb_limitdepth's best error=0.2653,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:38] {2219} INFO - iteration 202, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:11:40] {2398} INFO -  at 544.3s,\testimator xgb_limitdepth's best error=0.2653,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:40] {2219} INFO - iteration 203, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:11:42] {2398} INFO -  at 547.1s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:42] {2219} INFO - iteration 204, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:11:44] {2398} INFO -  at 549.1s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:44] {2219} INFO - iteration 205, current learner xgboost\n",
      "[flaml.automl.logger: 02-18 19:11:52] {2398} INFO -  at 556.4s,\testimator xgboost's best error=0.2644,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:52] {2219} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:11:55] {2398} INFO -  at 559.3s,\testimator xgb_limitdepth's best error=0.2653,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:55] {2219} INFO - iteration 207, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:11:56] {2398} INFO -  at 560.4s,\testimator xgb_limitdepth's best error=0.2653,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:56] {2219} INFO - iteration 208, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:11:56] {2398} INFO -  at 561.0s,\testimator rf's best error=0.2761,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:56] {2219} INFO - iteration 209, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:11:57] {2398} INFO -  at 561.6s,\testimator rf's best error=0.2738,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:57] {2219} INFO - iteration 210, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:11:58] {2398} INFO -  at 562.3s,\testimator rf's best error=0.2738,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:58] {2219} INFO - iteration 211, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:11:58] {2398} INFO -  at 562.9s,\testimator rf's best error=0.2732,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:58] {2219} INFO - iteration 212, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:11:59] {2398} INFO -  at 563.5s,\testimator rf's best error=0.2732,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:11:59] {2219} INFO - iteration 213, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:12:00] {2398} INFO -  at 564.2s,\testimator rf's best error=0.2732,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:00] {2219} INFO - iteration 214, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:12:00] {2398} INFO -  at 564.8s,\testimator rf's best error=0.2732,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:00] {2219} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:12:05] {2398} INFO -  at 569.2s,\testimator xgb_limitdepth's best error=0.2652,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:05] {2219} INFO - iteration 216, current learner extra_tree\n",
      "[flaml.automl.logger: 02-18 19:12:15] {2398} INFO -  at 580.0s,\testimator extra_tree's best error=0.2680,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:15] {2219} INFO - iteration 217, current learner rf\n",
      "[flaml.automl.logger: 02-18 19:12:16] {2398} INFO -  at 580.7s,\testimator rf's best error=0.2732,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:16] {2219} INFO - iteration 218, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-18 19:12:17] {2398} INFO -  at 581.8s,\testimator xgb_limitdepth's best error=0.2652,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:17] {2219} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:12:18] {2398} INFO -  at 582.9s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:18] {2219} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:12:28] {2398} INFO -  at 592.9s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:28] {2219} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 02-18 19:12:35] {2398} INFO -  at 599.8s,\testimator lgbm's best error=0.2641,\tbest estimator lgbm's best error=0.2641\n",
      "[flaml.automl.logger: 02-18 19:12:38] {2628} INFO - retrain lgbm for 2.3s\n",
      "[flaml.automl.logger: 02-18 19:12:38] {2631} INFO - retrained model: LGBMClassifier(learning_rate=0.06477299614831299, max_bin=1023,\n",
      "               min_child_samples=19, n_estimators=1, n_jobs=-1, num_leaves=20,\n",
      "               reg_alpha=0.001975258376030875, reg_lambda=11.596637744505859,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 02-18 19:12:38] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 02-18 19:12:38] {1932} INFO - Time taken to find the best model: 87.68760514259338\n",
      "LGBMClassifier(learning_rate=0.06477299614831299, max_bin=1023,\n",
      "               min_child_samples=19, n_estimators=1, n_jobs=-1, num_leaves=20,\n",
      "               reg_alpha=0.001975258376030875, reg_lambda=11.596637744505859,\n",
      "               verbose=-1)\n",
      "\n",
      "--- Model Performance ---\n",
      "Model Accuracy: 0.7454160084781348\n",
      "Model F1 Score: 0.1856210822566202\n",
      "Model AUC: 0.7390218191837277\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from flaml import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# AutoML 초기화 (로그 출력을 줄이기 위해 log_type 설정)\n",
    "automl = AutoML(\n",
    "    log_type=\"silent\",\n",
    "    metric='roc_auc',  # 최적화할 평가 지표\n",
    "    time_budget=60*10,  # 학습에 사용할 최대 시간 (초)\n",
    "    task=\"classification\",  # 분류\n",
    "    )\n",
    "\n",
    "# 모델 학습\n",
    "automl.fit(X_train=IVF_X_train, y_train=IVF_y_train)\n",
    "\n",
    "# 최적의 모델 출력\n",
    "print(automl.model.estimator)\n",
    "\n",
    "# 예측\n",
    "y_pred = automl.predict(IVF_X_test)\n",
    "y_pred_proba = automl.predict_proba(IVF_X_test)[:, 1]\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(IVF_y_test, y_pred)\n",
    "f1 = f1_score(IVF_y_test, y_pred)\n",
    "auc = roc_auc_score(IVF_y_test, y_pred_proba)\n",
    "cm = confusion_matrix(IVF_y_test, y_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print()\n",
    "print(\"--- Model Performance ---\")\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(f\"Model F1 Score: {f1}\")\n",
    "print(f\"Model AUC: {auc}\")\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=automl.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
